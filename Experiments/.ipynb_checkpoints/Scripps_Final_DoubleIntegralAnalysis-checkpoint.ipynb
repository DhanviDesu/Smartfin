{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a PSD plot framework for future plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Purisa Jasmine Simmons\n",
    "#Viren Abhyankar\n",
    "#February 2020\n",
    "\n",
    "#Overview: Trying to generate a PSD plot (framework for future plots).\n",
    "#Based on Method V of this paper: https://journals.ametsoc.org/doi/pdf/10.1175/2010JTECHO724.1\n",
    "\n",
    "#First, parse the data from the .CSV file.\n",
    "#This data comes from Scripps buoy that recalibrates every 30 minutes \n",
    "#all of the vertical accelerations are contained in IMUA2.\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import constants\n",
    "from scipy import signal #added\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import simps\n",
    "from scipy.integrate import cumtrapz\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "import peakutils\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "from plotly import tools #added all the plotly's\n",
    "import plotly.offline\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import math #added\n",
    "import re   #added\n",
    "\n",
    "# For the definition of the abstract base class IMU_Base\n",
    "import abc\n",
    "\n",
    "import sys\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                                 ID  \\\n",
      "0           0  google_106807627751629413403_0006667E228C_1709...   \n",
      "1           1  google_106807627751629413403_0006667E228C_1709...   \n",
      "2           2  google_106807627751629413403_0006667E228C_1709...   \n",
      "3           3  google_106807627751629413403_0006667E228C_1709...   \n",
      "4           4  google_106807627751629413403_0006667E228C_1709...   \n",
      "\n",
      "                              UTC   Time    IMU A1     IMU A2    IMU A3  \\\n",
      "0  2017-09-09T18:02:11.2810+00:00  18:02  0.000000  11.070788  0.134075   \n",
      "1  2017-09-09T18:02:11.4800+00:00  18:02 -0.325611  11.185710 -0.459687   \n",
      "2  2017-09-09T18:02:11.7310+00:00  18:02  0.000000  10.419566  1.800440   \n",
      "3  2017-09-09T18:02:11.9810+00:00  18:02  0.823605  10.860099 -0.114922   \n",
      "4  2017-09-09T18:02:12.1800+00:00  18:02  0.670376  11.492168 -0.651223   \n",
      "\n",
      "      IMU G1     IMU G2     IMU G3  IMU M1  IMU M2  IMU M3        Date  \\\n",
      "0  46.829268  15.853659  15.487805   -37.0  -199.0   517.0  2017-09-09   \n",
      "1   8.902439  -2.439024  12.073171   -33.0  -179.0   533.0  2017-09-09   \n",
      "2 -16.341463   1.463415  14.268293   -46.0  -188.0   528.0  2017-09-09   \n",
      "3  -5.731707  17.439024  21.707317   -64.0  -186.0   522.0  2017-09-09   \n",
      "4 -28.658537   1.219512  21.341463   -91.0  -175.0   493.0  2017-09-09   \n",
      "\n",
      "      Hs(m)  Tp(s)  Dp(deg)  \n",
      "0  0.841248   5.88    284.0  \n",
      "1  0.841248   5.88    284.0  \n",
      "2  0.841248   5.88    284.0  \n",
      "3  0.841248   5.88    284.0  \n",
      "4  0.841248   5.88    284.0  \n",
      "1538168\n"
     ]
    }
   ],
   "source": [
    "## Read from CSV\n",
    "#Full csv:\n",
    "#scripps_final_combined = pd.read_csv('Scripps_Final_Combined.csv')\n",
    "#print(scripps_final_combined.head())\n",
    "\n",
    "#Gets all columns\n",
    "motion_df = pd.read_csv('Scripps_Final_Combined.csv')\n",
    "#motion_df = motion_df.drop(['Time'], axis=1)\n",
    "print(motion_df.head())\n",
    "print(len(motion_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a copy of the original motion_df dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(motion_df)\n",
    "\n",
    "saved_copy_motion_df = motion_df.copy(deep=True) #make a copy of the dataframe with raw data included\n",
    "\n",
    "#print(saved_copy_motion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualting time_elapseds, time_offsets and creating IMU1, IMU2, and IMU3 raw data lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55182\n",
      "7551\n",
      "0.4767580452920143\n"
     ]
    }
   ],
   "source": [
    "#Reading data from Scripps_Final_Combined.csv\n",
    "#The name of the motion dataframe is: motion_df\n",
    "\n",
    "#Get times from the \"Time\" column to create time_o_list and time_e_list.\n",
    "#Get imus from the \"IMU A[*]\" column to create the imu acc arrays. \n",
    "\n",
    "#Analyze following time period:\n",
    "#Can use np.where()[0][0] for the following:\n",
    "#9/9/2017 - 18:10 to 18:40\n",
    "#6/14/2018 - 15:20 to 16:20\n",
    "\n",
    "#Analyze particular UTC with actual heights (m) -- 30 minute sessions\n",
    "# 2017-09-09T18:24:00.1810+00:00 to 2017-09-09T18:54:00.1810+00:00 -- 0.810768\n",
    "# 2017-09-09T18:54:00.1810+00:00 to 2018-06-14T15:13:06.7140+00:00 -- 0.819912\n",
    "# 2018-06-14T15:13:06.7140+00:00 to 2018-06-14T15:43:00.0050+00:00 -- 0.679704\n",
    "# 2018-06-14T15:43:00.0050+00:00 to 2018-06-14T16:13:00.2150+00:00 -- 0.70104\n",
    "# 2019-05-29T15:21:41.0170+00:00 to 2019-05-29T15:51:00.0140+00:00 -- 1.069848\n",
    "# 2019-05-29T15:51:00.0140+00:00 to 2019-05-29T16:21:00.0620+00:00 -- 1.179576\n",
    "# 2019-05-29T16:21:00.0620+00:00 to 2019-05-29T16:51:00.1630+00:00 -- 1.179576\n",
    "\n",
    "START = '2019-05-29T16:21:00.0620+00:00'\n",
    "END = '2019-05-29T16:51:00.1630+00:00'\n",
    "\n",
    "time_e_array = []\n",
    "\n",
    "time_array = motion_df[['Time']].to_numpy()\n",
    "utc_time = motion_df[['UTC']].to_numpy()\n",
    "\n",
    "start_index = np.where(utc_time==START)[0][0]\n",
    "end_index = np.where(utc_time==END)[0][0]\n",
    "\n",
    "#Convert time strings into seconds\n",
    "#start_index = np.where(time_array=='15:20')[0][0]\n",
    "#end_index = np.where(time_array=='16:20')[0][0]\n",
    "\n",
    "length = end_index-start_index\n",
    "print(length)\n",
    "\n",
    "mins_per_measure = 60/length\n",
    "sec_per_measure = 60*mins_per_measure\n",
    "\n",
    "print(sec_per_measure)\n",
    "\n",
    "#start_time = 18*3600 + 10*60\n",
    "\n",
    "for i in range(0, length):\n",
    "    time_e_array.append(sec_per_measure*i)\n",
    "    \n",
    "imu_array1 = motion_df.loc[start_index:end_index-1,'IMU A1'].to_numpy()\n",
    "imu_array2 = motion_df.loc[start_index:end_index-1,'IMU A2'].to_numpy()\n",
    "imu_array3 = motion_df.loc[start_index:end_index-1,'IMU A3'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:23\n"
     ]
    }
   ],
   "source": [
    "# Function to parse time string and calculate half hour\n",
    "def add_half_hour(time_str):\n",
    "    hrs = int(time_str[:2])\n",
    "    mins = int(time_str[3:5])\n",
    "    if (mins < 30):\n",
    "        mins += 30\n",
    "    else:\n",
    "        mins -= 30\n",
    "        if (hrs == 23):\n",
    "            hrs = 0\n",
    "        else:\n",
    "            hrs += 1\n",
    "            \n",
    "    if (mins < 10):\n",
    "        mins = '0'+str(mins)\n",
    "    if (hrs < 10):\n",
    "        hrs = '0'+str(hrs)\n",
    "        \n",
    "    return str(hrs)+':'+str(mins)\n",
    "\n",
    "print(add_half_hour('18:53'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  1  and Ride:  ['2017-09-09']\n",
      "At  18:10  and  18:40\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  2  and Ride:  ['2017-09-09']\n",
      "At  18:40  and  19:10\n",
      "Start:  [0.819912]  and End:  [0.819912] \n",
      "\n",
      "Session:  3  and Ride:  ['2018-06-14']\n",
      "At  15:20  and  15:50\n",
      "Start:  [0.70104]  and End:  [0.70104] \n",
      "\n",
      "Session:  4  and Ride:  ['2018-06-14']\n",
      "At  15:50  and  16:20\n",
      "Start:  [0.710184]  and End:  [0.710184] \n",
      "\n",
      "Session:  5  and Ride:  ['2019-05-29']\n",
      "At  15:50  and  16:20\n",
      "Start:  [1.069848]  and End:  [1.069848] \n",
      "\n",
      "Session:  6  and Ride:  ['2019-05-29']\n",
      "At  16:20  and  16:50\n",
      "Start:  [1.179576]  and End:  [1.179576] \n",
      "\n",
      "Session:  7  and Ride:  ['2018-08-12']\n",
      "At  14:46  and  15:16\n",
      "Start:  [0.618744]  and End:  [0.618744] \n",
      "\n",
      "Session:  8  and Ride:  ['2018-08-12']\n",
      "At  15:20  and  15:50\n",
      "Start:  [0.649224]  and End:  [0.649224] \n",
      "\n",
      "Session:  9  and Ride:  ['2017-08-08']\n",
      "At  16:40  and  17:10\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  10  and Ride:  ['2017-08-08']\n",
      "At  17:10  and  17:40\n",
      "Start:  [0.911352]  and End:  [0.911352] \n",
      "\n",
      "Session:  11  and Ride:  ['2017-08-08']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.890016]  and End:  [0.890016] \n",
      "\n",
      "Session:  12  and Ride:  ['2017-06-23']\n",
      "At  18:40  and  19:10\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  13  and Ride:  ['2017-06-23']\n",
      "At  19:10  and  19:40\n",
      "Start:  [0.798576]  and End:  [0.798576] \n",
      "\n",
      "Session:  14  and Ride:  ['2017-06-23']\n",
      "At  19:40  and  20:10\n",
      "Start:  [0.780288]  and End:  [0.780288] \n",
      "\n",
      "Session:  15  and Ride:  ['2018-05-14']\n",
      "At  18:20  and  18:50\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  16  and Ride:  ['2018-05-14']\n",
      "At  18:50  and  19:20\n",
      "Start:  [0.789432]  and End:  [0.789432] \n",
      "\n",
      "Session:  17  and Ride:  ['2017-09-19']\n",
      "At  20:10  and  20:40\n",
      "Start:  [0.841248]  and End:  [0.841248] \n",
      "\n",
      "Session:  18  and Ride:  ['2017-07-31']\n",
      "At  18:49  and  19:19\n",
      "Start:  [0.841248]  and End:  [0.841248] \n",
      "\n",
      "Session:  19  and Ride:  ['2018-08-28']\n",
      "At  17:20  and  17:50\n",
      "Start:  [0.841248]  and End:  [0.841248] \n",
      "\n",
      "Session:  20  and Ride:  ['2017-08-28']\n",
      "At  21:10  and  21:40\n",
      "Start:  [0.688848]  and End:  [0.688848] \n",
      "\n",
      "Session:  21  and Ride:  ['2018-09-02']\n",
      "At  16:50  and  17:20\n",
      "Start:  [0.92964]  and End:  [0.92964] \n",
      "\n",
      "Session:  22  and Ride:  ['2018-09-02']\n",
      "At  17:20  and  17:50\n",
      "Start:  [0.841248]  and End:  [0.841248] \n",
      "\n",
      "Session:  23  and Ride:  ['2018-09-02']\n",
      "At  17:50  and  18:20\n",
      "Start:  [0.780288]  and End:  [0.780288] \n",
      "\n",
      "Session:  24  and Ride:  ['2018-10-31']\n",
      "At  15:50  and  16:20\n",
      "Start:  [1.118616]  and End:  [1.118616] \n",
      "\n",
      "Session:  25  and Ride:  ['2017-09-21']\n",
      "At  00:10  and  00:40\n",
      "Start:  [0.911352]  and End:  [0.911352] \n",
      "\n",
      "Session:  26  and Ride:  ['2017-09-21']\n",
      "At  00:40  and  01:10\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  27  and Ride:  ['2017-05-31']\n",
      "At  19:10  and  19:40\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  28  and Ride:  ['2017-05-31']\n",
      "At  19:40  and  20:10\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  29  and Ride:  ['2018-08-13']\n",
      "At  16:50  and  17:20\n",
      "Start:  [0.6096]  and End:  [0.6096] \n",
      "\n",
      "Session:  30  and Ride:  ['2018-09-14']\n",
      "At  14:50  and  15:20\n",
      "Start:  [0.859536]  and End:  [0.859536] \n",
      "\n",
      "Session:  31  and Ride:  ['2018-09-14']\n",
      "At  15:20  and  15:50\n",
      "Start:  [0.880872]  and End:  [0.880872] \n",
      "\n",
      "Session:  32  and Ride:  ['2018-04-03']\n",
      "At  16:20  and  16:50\n",
      "Start:  [0.460248]  and End:  [0.460248] \n",
      "\n",
      "Session:  33  and Ride:  ['2018-04-03']\n",
      "At  16:50  and  17:20\n",
      "Start:  [0.460248]  and End:  [0.460248] \n",
      "\n",
      "Session:  34  and Ride:  ['2017-06-23']\n",
      "At  18:40  and  19:10\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  35  and Ride:  ['2017-06-23']\n",
      "At  19:10  and  19:40\n",
      "Start:  [0.798576]  and End:  [0.798576] \n",
      "\n",
      "Session:  36  and Ride:  ['2017-06-23']\n",
      "At  19:40  and  20:10\n",
      "Start:  [0.780288]  and End:  [0.780288] \n",
      "\n",
      "Session:  37  and Ride:  ['2019-01-04']\n",
      "At  17:20  and  17:50\n",
      "Start:  [0.420624]  and End:  [0.420624] \n",
      "\n",
      "Session:  38  and Ride:  ['2019-01-04']\n",
      "At  17:50  and  18:20\n",
      "Start:  [0.41148]  and End:  [0.41148] \n",
      "\n",
      "Session:  39  and Ride:  ['2017-05-20']\n",
      "At  00:40  and  01:10\n",
      "Start:  [0.679704]  and End:  [0.679704] \n",
      "\n",
      "Session:  40  and Ride:  ['2017-05-20']\n",
      "At  01:10  and  01:40\n",
      "Start:  [0.749808]  and End:  [0.749808] \n",
      "\n",
      "Session:  41  and Ride:  ['2017-12-20']\n",
      "At  17:10  and  17:40\n",
      "Start:  [0.469392]  and End:  [0.469392] \n",
      "\n",
      "Session:  42  and Ride:  ['2017-12-20']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.460248]  and End:  [0.460248] \n",
      "\n",
      "Session:  43  and Ride:  ['2017-10-20']\n",
      "At  23:10  and  23:40\n",
      "Start:  [1.469136]  and End:  [1.469136] \n",
      "\n",
      "Session:  44  and Ride:  ['2017-10-20']\n",
      "At  23:40  and  00:10\n",
      "Start:  [1.560576]  and End:  [1.560576] \n",
      "\n",
      "Session:  45  and Ride:  ['2018-10-22']\n",
      "At  16:20  and  16:50\n",
      "Start:  [0.618744]  and End:  [0.618744] \n",
      "\n",
      "Session:  46  and Ride:  ['2018-10-22']\n",
      "At  16:50  and  17:20\n",
      "Start:  [0.600456]  and End:  [0.600456] \n",
      "\n",
      "Session:  47  and Ride:  ['2017-09-09']\n",
      "At  18:10  and  18:40\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  48  and Ride:  ['2017-09-09']\n",
      "At  18:40  and  19:10\n",
      "Start:  [0.819912]  and End:  [0.819912] \n",
      "\n",
      "Session:  49  and Ride:  ['2019-06-15']\n",
      "At  20:20  and  20:50\n",
      "Start:  [0.569976]  and End:  [0.569976] \n",
      "\n",
      "Session:  50  and Ride:  ['2017-07-21']\n",
      "At  01:10  and  01:40\n",
      "Start:  [0.679704]  and End:  [0.679704] \n",
      "\n",
      "Session:  51  and Ride:  ['2017-07-21']\n",
      "At  01:40  and  02:10\n",
      "Start:  [0.630936]  and End:  [0.630936] \n",
      "\n",
      "Session:  52  and Ride:  ['2017-08-23']\n",
      "At  16:10  and  16:40\n",
      "Start:  [0.710184]  and End:  [0.710184] \n",
      "\n",
      "Session:  53  and Ride:  ['2017-08-23']\n",
      "At  16:40  and  17:10\n",
      "Start:  [0.749808]  and End:  [0.749808] \n",
      "\n",
      "Session:  54  and Ride:  ['2017-10-10']\n",
      "At  16:38  and  17:08\n",
      "Start:  [0.618744]  and End:  [0.618744] \n",
      "\n",
      "Session:  55  and Ride:  ['2017-10-10']\n",
      "At  17:10  and  17:40\n",
      "Start:  [0.67056]  and End:  [0.67056] \n",
      "\n",
      "Session:  56  and Ride:  ['2017-06-22']\n",
      "At  19:40  and  20:10\n",
      "Start:  [0.92964]  and End:  [0.92964] \n",
      "\n",
      "Session:  57  and Ride:  ['2017-06-18']\n",
      "At  23:10  and  23:40\n",
      "Start:  [0.89916]  and End:  [0.89916] \n",
      "\n",
      "Session:  58  and Ride:  ['2017-06-18']\n",
      "At  23:40  and  00:10\n",
      "Start:  [1.078992]  and End:  [1.078992] \n",
      "\n",
      "Session:  59  and Ride:  ['2018-07-11']\n",
      "At  16:50  and  17:20\n",
      "Start:  [0.438912]  and End:  [0.438912] \n",
      "\n",
      "Session:  60  and Ride:  ['2017-06-28']\n",
      "At  22:10  and  22:40\n",
      "Start:  [0.798576]  and End:  [0.798576] \n",
      "\n",
      "Session:  61  and Ride:  ['2017-09-21']\n",
      "At  21:11  and  21:41\n",
      "Start:  [1.091184]  and End:  [1.091184] \n",
      "\n",
      "Session:  62  and Ride:  ['2017-06-28']\n",
      "At  22:10  and  22:40\n",
      "Start:  [0.798576]  and End:  [0.798576] \n",
      "\n",
      "Session:  63  and Ride:  ['2017-06-30']\n",
      "At  01:40  and  02:10\n",
      "Start:  [0.6096]  and End:  [0.6096] \n",
      "\n",
      "Session:  64  and Ride:  ['2017-06-30']\n",
      "At  02:10  and  02:40\n",
      "Start:  [0.539496]  and End:  [0.539496] \n",
      "\n",
      "Session:  65  and Ride:  ['2017-12-04']\n",
      "At  18:56  and  19:26\n",
      "Start:  [0.86868]  and End:  [0.86868] \n",
      "\n",
      "Session:  66  and Ride:  ['2017-06-24']\n",
      "At  21:40  and  22:10\n",
      "Start:  [0.911352]  and End:  [0.911352] \n",
      "\n",
      "Session:  67  and Ride:  ['2017-06-24']\n",
      "At  22:10  and  22:40\n",
      "Start:  [0.86868]  and End:  [0.86868] \n",
      "\n",
      "Session:  68  and Ride:  ['2018-11-09']\n",
      "At  19:21  and  19:51\n",
      "Start:  [0.438912]  and End:  [0.438912] \n",
      "\n",
      "Session:  69  and Ride:  ['2017-06-16']\n",
      "At  21:10  and  21:40\n",
      "Start:  [0.841248]  and End:  [0.841248] \n",
      "\n",
      "Session:  70  and Ride:  ['2017-06-16']\n",
      "At  21:40  and  22:10\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  71  and Ride:  ['2017-08-29']\n",
      "At  18:37  and  19:07\n",
      "Start:  [0.70104]  and End:  [0.70104] \n",
      "\n",
      "Session:  72  and Ride:  ['2017-08-29']\n",
      "At  19:10  and  19:40\n",
      "Start:  [0.710184]  and End:  [0.710184] \n",
      "\n",
      "Session:  73  and Ride:  ['2017-10-04']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.591312]  and End:  [0.591312] \n",
      "\n",
      "Session:  74  and Ride:  ['2017-10-11']\n",
      "At  23:10  and  23:40\n",
      "Start:  [0.54864]  and End:  [0.54864] \n",
      "\n",
      "Session:  75  and Ride:  ['2019-06-15']\n",
      "At  20:20  and  20:50\n",
      "Start:  [0.569976]  and End:  [0.569976] \n",
      "\n",
      "Session:  76  and Ride:  ['2018-04-10']\n",
      "At  00:20  and  00:50\n",
      "Start:  [1.240536]  and End:  [1.240536] \n",
      "\n",
      "Session:  77  and Ride:  ['2017-06-28']\n",
      "At  00:40  and  01:10\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  78  and Ride:  ['2017-06-28']\n",
      "At  01:10  and  01:40\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  79  and Ride:  ['2017-06-28']\n",
      "At  00:40  and  01:10\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  80  and Ride:  ['2017-06-28']\n",
      "At  01:10  and  01:40\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  81  and Ride:  ['2018-09-10']\n",
      "At  17:50  and  18:20\n",
      "Start:  [0.89916]  and End:  [0.89916] \n",
      "\n",
      "Session:  82  and Ride:  ['2018-09-10']\n",
      "At  18:20  and  18:50\n",
      "Start:  [0.938784]  and End:  [0.938784] \n",
      "\n",
      "Session:  83  and Ride:  ['2017-07-02']\n",
      "At  02:10  and  02:40\n",
      "Start:  [0.688848]  and End:  [0.688848] \n",
      "\n",
      "Session:  84  and Ride:  ['2017-07-02']\n",
      "At  02:40  and  03:10\n",
      "Start:  [0.70104]  and End:  [0.70104] \n",
      "\n",
      "Session:  85  and Ride:  ['2017-12-04']\n",
      "At  19:05  and  19:35\n",
      "Start:  [0.86868]  and End:  [0.86868] \n",
      "\n",
      "Session:  86  and Ride:  ['2017-12-04']\n",
      "At  19:40  and  20:10\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  87  and Ride:  ['2018-11-04']\n",
      "At  21:20  and  21:50\n",
      "Start:  [0.6096]  and End:  [0.6096] \n",
      "\n",
      "Session:  88  and Ride:  ['2018-11-04']\n",
      "At  21:50  and  22:20\n",
      "Start:  [0.560832]  and End:  [0.560832] \n",
      "\n",
      "Session:  89  and Ride:  ['2019-02-08']\n",
      "At  17:50  and  18:20\n",
      "Start:  [0.469392]  and End:  [0.469392] \n",
      "\n",
      "Session:  90  and Ride:  ['2019-02-08']\n",
      "At  18:20  and  18:50\n",
      "Start:  [0.451104]  and End:  [0.451104] \n",
      "\n",
      "Session:  91  and Ride:  ['2018-06-05']\n",
      "At  15:18  and  15:48\n",
      "Start:  [0.560832]  and End:  [0.560832] \n",
      "\n",
      "Session:  92  and Ride:  ['2018-06-05']\n",
      "At  15:48  and  16:18\n",
      "Start:  [0.560832]  and End:  [0.560832] \n",
      "\n",
      "Session:  93  and Ride:  ['2018-06-05']\n",
      "At  16:20  and  16:50\n",
      "Start:  [0.521208]  and End:  [0.521208] \n",
      "\n",
      "Session:  94  and Ride:  ['2017-09-07']\n",
      "At  18:40  and  19:10\n",
      "Start:  [0.789432]  and End:  [0.789432] \n",
      "\n",
      "Session:  95  and Ride:  ['2017-09-07']\n",
      "At  19:10  and  19:40\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  96  and Ride:  ['2017-09-07']\n",
      "At  19:40  and  20:10\n",
      "Start:  [0.810768]  and End:  [0.810768] \n",
      "\n",
      "Session:  97  and Ride:  ['2017-06-30']\n",
      "At  01:40  and  02:10\n",
      "Start:  [0.6096]  and End:  [0.6096] \n",
      "\n",
      "Session:  98  and Ride:  ['2017-06-30']\n",
      "At  02:10  and  02:40\n",
      "Start:  [0.539496]  and End:  [0.539496] \n",
      "\n",
      "Session:  99  and Ride:  ['2017-09-08']\n",
      "At  23:40  and  00:10\n",
      "Start:  [0.740664]  and End:  [0.740664] \n",
      "\n",
      "Session:  100  and Ride:  ['2017-09-09']\n",
      "At  00:10  and  00:40\n",
      "Start:  [0.780288]  and End:  [0.780288] \n",
      "\n",
      "Session:  101  and Ride:  ['2017-08-02']\n",
      "At  16:59  and  17:29\n",
      "Start:  [0.64008]  and End:  [0.64008] \n",
      "\n",
      "Session:  102  and Ride:  ['2017-08-02']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.630936]  and End:  [0.630936] \n",
      "\n",
      "Session:  103  and Ride:  ['2017-06-24']\n",
      "At  21:40  and  22:10\n",
      "Start:  [0.911352]  and End:  [0.911352] \n",
      "\n",
      "Session:  104  and Ride:  ['2017-06-24']\n",
      "At  22:10  and  22:40\n",
      "Start:  [0.86868]  and End:  [0.86868] \n",
      "\n",
      "Session:  105  and Ride:  ['2017-06-23']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.73152]  and End:  [0.73152] \n",
      "\n",
      "Session:  106  and Ride:  ['2017-08-10']\n",
      "At  16:40  and  17:10\n",
      "Start:  [0.880872]  and End:  [0.880872] \n",
      "\n",
      "Session:  107  and Ride:  ['2017-08-10']\n",
      "At  17:10  and  17:40\n",
      "Start:  [0.780288]  and End:  [0.780288] \n",
      "\n",
      "Session:  108  and Ride:  ['2017-08-10']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.819912]  and End:  [0.819912] \n",
      "\n",
      "Session:  109  and Ride:  ['2017-06-26']\n",
      "At  22:39  and  23:09\n",
      "Start:  [0.649224]  and End:  [0.649224] \n",
      "\n",
      "Session:  110  and Ride:  ['2017-06-26']\n",
      "At  23:10  and  23:40\n",
      "Start:  [0.688848]  and End:  [0.688848] \n",
      "\n",
      "Session:  111  and Ride:  ['2017-06-26']\n",
      "At  23:40  and  00:10\n",
      "Start:  [0.70104]  and End:  [0.70104] \n",
      "\n",
      "Session:  112  and Ride:  ['2017-07-02']\n",
      "At  02:10  and  02:40\n",
      "Start:  [0.688848]  and End:  [0.688848] \n",
      "\n",
      "Session:  113  and Ride:  ['2017-07-02']\n",
      "At  02:40  and  03:10\n",
      "Start:  [0.70104]  and End:  [0.70104] \n",
      "\n",
      "Session:  114  and Ride:  ['2017-06-26']\n",
      "At  23:10  and  23:40\n",
      "Start:  [0.688848]  and End:  [0.688848] \n",
      "\n",
      "Session:  115  and Ride:  ['2017-06-26']\n",
      "At  23:40  and  00:10\n",
      "Start:  [0.70104]  and End:  [0.70104] \n",
      "\n",
      "Session:  116  and Ride:  ['2018-04-15']\n",
      "At  18:20  and  18:50\n",
      "Start:  [0.819912]  and End:  [0.819912] \n",
      "\n",
      "Session:  117  and Ride:  ['2018-04-15']\n",
      "At  18:50  and  19:20\n",
      "Start:  [0.829056]  and End:  [0.829056] \n",
      "\n",
      "Session:  118  and Ride:  ['2018-09-12']\n",
      "At  01:20  and  01:50\n",
      "Start:  [0.841248]  and End:  [0.841248] \n",
      "\n",
      "Session:  119  and Ride:  ['2018-09-12']\n",
      "At  01:50  and  02:20\n",
      "Start:  [0.880872]  and End:  [0.880872] \n",
      "\n",
      "Session:  120  and Ride:  ['2018-08-12']\n",
      "At  14:45  and  15:15\n",
      "Start:  [0.618744]  and End:  [0.618744] \n",
      "\n",
      "Session:  121  and Ride:  ['2018-08-12']\n",
      "At  15:20  and  15:50\n",
      "Start:  [0.649224]  and End:  [0.649224] \n",
      "\n",
      "Session:  122  and Ride:  ['2017-10-20']\n",
      "At  23:10  and  23:40\n",
      "Start:  [1.469136]  and End:  [1.469136] \n",
      "\n",
      "Session:  123  and Ride:  ['2017-10-20']\n",
      "At  23:40  and  00:10\n",
      "Start:  [1.560576]  and End:  [1.560576] \n",
      "\n",
      "Session:  124  and Ride:  ['2017-06-28']\n",
      "At  00:40  and  01:10\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  125  and Ride:  ['2017-06-28']\n",
      "At  01:10  and  01:40\n",
      "Start:  [0.920496]  and End:  [0.920496] \n",
      "\n",
      "Session:  126  and Ride:  ['2017-10-26']\n",
      "At  17:40  and  18:10\n",
      "Start:  [0.521208]  and End:  [0.521208] \n",
      "\n",
      "Session:  127  and Ride:  ['2017-10-26']\n",
      "At  18:10  and  18:40\n",
      "Start:  [0.560832]  and End:  [0.560832] \n",
      "\n",
      "Session:  128  and Ride:  ['2019-01-04']\n",
      "At  18:50  and  19:20\n",
      "Start:  [0.41148]  and End:  [0.41148] \n",
      "\n",
      "Session:  129  and Ride:  ['2019-01-04']\n",
      "At  19:20  and  19:50\n",
      "Start:  [0.381]  and End:  [0.381] \n",
      "\n",
      "Total sessions:  129\n"
     ]
    }
   ],
   "source": [
    "### Goal: create an array of arrays of IMU A2 data ###\n",
    "surf_sessions = []\n",
    "\n",
    "## Step 1: get 5 columns of the data frame to iterate over - ID, Time, IMU A2, Date, Height ##\n",
    "df_parser = motion_df[['ID', 'Time', 'IMU A2', 'Date', 'Hs(m)']]\n",
    "\n",
    "id_parser = df_parser[['ID']].to_numpy()\n",
    "time_parser = df_parser[['Time']].to_numpy()\n",
    "imuA2_parser = df_parser[['IMU A2']].to_numpy()\n",
    "date_parser = df_parser[['Date']].to_numpy()\n",
    "height_parser = df_parser[['Hs(m)']].to_numpy()\n",
    "\n",
    "## Step 2: loop through every data point ##\n",
    "working_array = []\n",
    "skip_check = '00:00'\n",
    "end_index_check = None\n",
    "\n",
    "for start_index in range(0, len(id_parser)):\n",
    "    ## Goal 1: Append IMU data if we are in the half-hour segment ##\n",
    "    \n",
    "    if (end_index_check != None):\n",
    "        # Check if we've reached the end of the half hour before appending\n",
    "        if (start_index==end_index_check):\n",
    "            surf_sessions.append(working_array)\n",
    "            working_array = []\n",
    "            end_index_check = None\n",
    "        else:\n",
    "            working_array.append(imuA2_parser[start_index][0])\n",
    "        continue\n",
    "        \n",
    "    ## Goal 2: Check if height of current and half-hour times are equal ##\n",
    "    \n",
    "    start = time_parser[start_index][0]\n",
    "    \n",
    "    # Skip through a minute if it has already been checked and invalidated\n",
    "    if (start==skip_check):\n",
    "        continue\n",
    "        \n",
    "    end = add_half_hour(start)\n",
    "    \n",
    "    # Check if ride is still valid for half hour time\n",
    "    try:\n",
    "        end_index = np.where((time_parser==end) & (id_parser==id_parser[start_index]))[0][0]\n",
    "        # Reset if ride is valid\n",
    "    except IndexError:\n",
    "        skip_check = start\n",
    "        continue\n",
    "    \n",
    "    if (height_parser[start_index]!=height_parser[end_index-1]):\n",
    "        skip_check = start\n",
    "    else:\n",
    "        working_array.append(imuA2_parser[start_index][0])\n",
    "        end_index_check = end_index\n",
    "        \n",
    "        print(\"Session: \", len(surf_sessions)+1, \" and Ride: \", date_parser[start_index])\n",
    "        print(\"At \", start, \" and \", end)\n",
    "        print(\"Start: \", height_parser[start_index], \" and End: \", height_parser[end_index-1], \"\\n\")\n",
    "    \n",
    "print(\"Total sessions: \", len(surf_sessions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raw units to actual units (acc to [m/s^2]) and (time to [s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert raw units to actual units (acc to [m/s^2]) and (time to [s])\n",
    "\n",
    "\n",
    "#Raw acceleration constant 512 = 1g (accelerometer's measured force due to gravity)\n",
    "g_const = 512\n",
    "\n",
    "#Approximate measurement for gravity:\n",
    "gravity = 9.80665\n",
    "\n",
    "\n",
    "# Correct the IMU Acceleration columns into units of meters\n",
    "# Dividing by 512 is equivalent to muliplying by 4 to correct the bit shifting by 2 places and dividing by 2048 to convert bits to G's\n",
    "# Multiplying by the 9.81 afterwards is simply to convert G's into m/s^2\n",
    "\n",
    "def convert_acc_units(acc_array):\n",
    "    ret_array = []\n",
    "    for a in acc_array:\n",
    "        #Acceleration is now in m/s^2, need to subtract gravity from vertical axis. (??)\n",
    "        new_a = a / g_const * gravity + gravity\n",
    "        ret_array.append(new_a)\n",
    "    return ret_array\n",
    "\n",
    "#imu1_array = convert_acc_units(imu_array1) #new units in m/s^2\n",
    "#imu2_array = convert_acc_units(imu_array2) #new units in m/s^2\n",
    "#imu3_array = convert_acc_units(imu_array3) #new units in m/s^2\n",
    "imu1_array = imu_array1\n",
    "imu2_array = imu_array2\n",
    "imu3_array = imu_array3\n",
    "\n",
    "##To check:\n",
    "#for x,y in zip(imu2_array, imu_array2):\n",
    "#    print(x,y)\n",
    "\n",
    "##To check:\n",
    "#for t in time_e_array:\n",
    "#    print(t)\n",
    "\n",
    "\n",
    "print(\"Graph of our entire experiment:\")\n",
    "\n",
    "plt.plot(time_e_array, imu2_array)\n",
    "#plt.ylim(-1,1)\n",
    "plt.show()\n",
    "\n",
    "#print(\"Why are the y-axis values so small?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Seperate each of the subexperiments into its own acc lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in time_e_array:\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate each of the subexperiments into its own acc lists.\n",
    "#i.e. subexperiment1 corresponds to acc1, (subexperiment2 => acc2), etc.\n",
    "\n",
    "time_e_list1 = []\n",
    "time_e_list2 = []\n",
    "time_e_list3 = []\n",
    "\n",
    "acc_list = []\n",
    "acc_list1 = []\n",
    "acc_list2 = []\n",
    "acc_list3 = []\n",
    "\n",
    "time_array = []\n",
    "acc_array = []\n",
    "\n",
    "\n",
    "#For our controlled experiments, we know that imu2 is the vertical axis\n",
    "acc_list = imu2_array\n",
    "time_array = time_e_array\n",
    "\n",
    "\n",
    "#i = 0\n",
    "#while (i < len(imu2_array)):\n",
    "#    imu2_array[i] = imu2_array[i] - gravity\n",
    "#    i = i + 1\n",
    "#print(imu2_array)\n",
    "\n",
    "i = 0\n",
    "while (i < (len(acc_list)) - 1):\n",
    "    if (time_e_array[i] >= 0 and time_e_array[i] <= 1200):\n",
    "        acc_list1.append(acc_list[i])\n",
    "        time_e_list1.append(time_e_array[i])\n",
    "    if (time_e_array[i] > 1200 and time_e_array[i] <= 2400):\n",
    "        acc_list2.append(acc_list[i])\n",
    "        time_e_list2.append(time_e_array[i])\n",
    "    if (time_e_array[i] > 2400 and time_e_array[i] <= 3600):\n",
    "        acc_list3.append(acc_list[i])\n",
    "        time_e_list3.append(time_e_array[i])\n",
    "    i = i + 1\n",
    "    \n",
    "#Plot the subexperiments to verify correctness:\n",
    "acc_array = np.array(acc_list)   #acc_list gets vertical acceleration from y-axis imu2\n",
    "\n",
    "\n",
    "time_array1 = np.array(time_e_list1)\n",
    "acc_array1 = np.array(acc_list1)\n",
    "time_array2 = np.array(time_e_list2)\n",
    "acc_array2 = np.array(acc_list2)\n",
    "time_array3 = np.array(time_e_list3)\n",
    "acc_array3 = np.array(acc_list3)\n",
    "  \n",
    "    \n",
    "##Plotting:\n",
    "f1 = plt.figure(figsize=(10,3))\n",
    "ax1 = f1.add_subplot(121)\n",
    "ax2 = f1.add_subplot(122)\n",
    "\n",
    "ax1.plot(time_array, acc_array)\n",
    "ax1.set_title(\"Acceleration vs. Time\")\n",
    "ax1.set_xlabel(\"Time [s]\")\n",
    "ax1.set_ylabel('Acceleration [m/s^2]')\n",
    "\n",
    "\n",
    "ax2.plot(time_array1, acc_array1)\n",
    "ax2.set_title(\"Acceleration1 vs. Time\")\n",
    "ax2.set_xlabel(\"Time [s]\")\n",
    "ax2.set_ylabel(\"Acceleration [m/s^2]\")\n",
    "#ax2.set_ylim([-6,6])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Detrend and Double Integrate the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PSD Step 2: Detrend the data \n",
    "dacc_array1 = signal.detrend(acc_array1)\n",
    "dacc_array2 = signal.detrend(acc_array2)\n",
    "dacc_array3 = signal.detrend(acc_array3)\n",
    "\n",
    "#f_s = 5.0 #sampling frequency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandpass filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First integral of acc to get velocity:\n",
    "from scipy import integrate\n",
    "\n",
    "def calculate_new_range(time_array, array_of_values, low_time, high_time):\n",
    "    new_time_array = []\n",
    "    new_value_array = []\n",
    "    for t,v in zip(time_array, array_of_values):\n",
    "        if (t >= low_time and t < high_time):\n",
    "            new_time_array.append(t)\n",
    "            new_value_array.append(v)\n",
    "    return new_time_array, new_value_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Butter Filters for Bandpass:\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_lfilter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def butter_bandpass_filtfilt(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "##Butter Filters for Highpass:\n",
    "def butter_highpass(highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, high, btype='high')\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_lfilter(data, highcut, fs, order=5):\n",
    "    b, a = butter_lowpass(highcut, fs, order=order)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "##Butter Filters for Lowpass:\n",
    "def butter_lowpass(lowcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    b, a = signal.butter(order, low, btype='low')\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_lfilter(data, lowcut, fs, order=5):\n",
    "    b, a = butter_lowpass(lowcut, fs, order=order)\n",
    "    y = signal.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the sample rate and the Low and High Cutoff frequencies\n",
    "fs = 30\n",
    "lowcut = 0.0333\n",
    "highcut = 1.5\n",
    "\n",
    "##Graphing the bandpass filters:\n",
    "butter_lfilter = butter_bandpass_lfilter(dacc_array1, lowcut, highcut, fs, order=5)\n",
    "butter_filtfilt = butter_bandpass_filtfilt(dacc_array1, lowcut, highcut, fs, order=5)\n",
    "\n",
    "\n",
    "###     Following code is NEVER USED \n",
    "'''\n",
    "new_time = time_array1.copy()\n",
    "\n",
    "for i in range(len(new_time)):\n",
    "    if i == 0:\n",
    "        new_time[i] = 0\n",
    "    else:\n",
    "        new_time[i] = new_time[i-1] + 1/fs\n",
    "'''\n",
    "### \n",
    "        \n",
    "\n",
    "\n",
    "fig1 = plt.figure(figsize=(15,8))\n",
    "ax1 = fig1.add_subplot(131)\n",
    "ax2 = fig1.add_subplot(132)\n",
    "ax3 = fig1.add_subplot(133)\n",
    "\n",
    "ax1.plot(time_array1, dacc_array1)\n",
    "ax1.set_title('Oritinal detrended Acceleration1')\n",
    "ax1.set_xlabel('Relative Time [sec]')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "ax1.axhline(0, color=\"orange\",ls='--')\n",
    "\n",
    "\n",
    "ax2.plot(time_array1, butter_lfilter)\n",
    "ax2.set_title('Butterpass Z Acceleration1 LFilter')\n",
    "ax2.set_xlabel('Relative Time [sec]')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "ax2.axhline(0, color=\"orange\",ls='--')\n",
    "\n",
    "ax3.plot(time_array1, butter_filtfilt)\n",
    "ax3.set_title('Butterpass Acceleration1 Filfilt')\n",
    "ax3.set_xlabel('Relative Time [sec]')\n",
    "ax3.set_ylabel('Amplitude')\n",
    "ax3.axhline(0, color=\"orange\",ls='--')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the sample rate and the Low and High Cutoff frequencies\n",
    "\n",
    "fs = 5 #redefine the sampling frequency\n",
    "\n",
    "order=6\n",
    "lowcut = 0.09\n",
    "highcut = 1.0\n",
    "\n",
    "def double_integral_bandpass(time_array, acc_array, dacc_array, lowcut, highcut, fs, order):\n",
    "    \n",
    "    butter_lfilter = butter_bandpass_lfilter(dacc_array, lowcut, highcut, fs, order=5)\n",
    "\n",
    "    \n",
    "    #First integral is the velocity:\n",
    "    v_integral = integrate.cumtrapz(x=time_array, y=butter_lfilter, initial=0)\n",
    "    detrend_v_integral = signal.detrend(v_integral)\n",
    "    \n",
    "    v_butter_filter_integral = butter_bandpass_lfilter(detrend_v_integral, lowcut, highcut, fs, order=5)\n",
    "    detrend_v_integral = signal.detrend(v_butter_filter_integral)\n",
    "\n",
    "\n",
    "    #Second integral is the displacment:\n",
    "    disp_integral = integrate.cumtrapz(x=time_array, y=v_butter_filter_integral, initial=0)\n",
    "    detrend_disp_integral = signal.detrend(disp_integral)\n",
    "    \n",
    "    disp_butter_filter_integral = butter_bandpass_lfilter(detrend_disp_integral, lowcut, highcut, fs, order=5)\n",
    "    detrend_disp_butter_integral = signal.detrend(disp_butter_filter_integral)\n",
    "\n",
    "\n",
    "\n",
    "    f1 = plt.figure(figsize=(12,5))\n",
    "    ax1 = f1.add_subplot(121)\n",
    "    ax2 = f1.add_subplot(122)\n",
    "\n",
    "    f2 = plt.figure(figsize=(12,5))\n",
    "    ax3 = f2.add_subplot(121)\n",
    "    ax4 = f2.add_subplot(122)\n",
    "    \n",
    "    f3 = plt.figure(figsize=(12,5))\n",
    "    ax5 = f3.add_subplot(121)\n",
    "    ax6 = f3.add_subplot(122)\n",
    "\n",
    "    #Acceleration graphs:\n",
    "    ax1.plot(time_array, dacc_array)\n",
    "    ax1.set_title('Detrended Acceleration vs. Time')\n",
    "    ax1.set_xlabel('Time [s]')\n",
    "    ax1.set_ylabel('Velocity [m/s]')\n",
    "    ax1.axhline(0, color=\"orange\", ls='--')\n",
    "    \n",
    "    ax2.plot(time_array, butter_lfilter)\n",
    "    ax2.set_title('Butter Filtered Detrended Acceleration vs. Time')\n",
    "    ax2.set_xlabel('Time [s]')\n",
    "    ax2.set_ylabel('Velocity [m/s]')\n",
    "    ax2.axhline(0, color=\"orange\", ls='--')\n",
    "    \n",
    "    #Velocity graphs:\n",
    "    ax3.plot(time_array, v_butter_filter_integral)\n",
    "    ax3.set_title('Butter Filtered Velocity vs. Time')\n",
    "    ax3.set_xlabel('Time [s]')\n",
    "    ax3.set_ylabel('Velocity [m/s]')\n",
    "    ax3.axhline(0, color=\"orange\", ls='--')\n",
    "\n",
    "\n",
    "    ax4.plot(time_array, detrend_v_integral)\n",
    "    ax4.set_title('Butter Filtered Detrended Velocity vs. Time')\n",
    "    ax4.set_xlabel('Time [s]')\n",
    "    ax4.set_ylabel('Velocity [m/s]')\n",
    "    ax4.axhline(0, color=\"orange\",ls='--')\n",
    "\n",
    "    \n",
    "    #Displacement graphs:\n",
    "    ax5.plot(time_array, disp_butter_filter_integral)\n",
    "    ax5.set_title('Butter Filtered Displacement vs. Time')\n",
    "    ax5.set_xlabel('Time [s]')\n",
    "    ax5.set_ylabel('Displacement [m]')               \n",
    "    \n",
    "    ax6.plot(time_array, detrend_disp_butter_integral)\n",
    "    ax6.set_title('Detrended Butter Filtered Displacement vs. Time')\n",
    "    ax6.set_xlabel('Time [s]')\n",
    "    ax6.set_ylabel('Displacement [m]')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return detrend_disp_butter_integral\n",
    "\n",
    "    \n",
    "    \n",
    "##For subexperiment1:\n",
    "print(\"Starting subexperiment 1 analysis:\")\n",
    "#Get as close to just the signal (don't want noise)    \n",
    "new_t1, new_acc1 = calculate_new_range(time_array1, acc_array1, 0, 1200)    \n",
    "new_t1, new_dacc1 = calculate_new_range(time_array1, dacc_array1, 0, 1200)\n",
    "disp_butter_integral1 = double_integral_bandpass(new_t1, new_acc1, new_dacc1, lowcut, highcut, fs, order)\n",
    "print(\"Done.\")\n",
    "\n",
    "##For subexperiment2:\n",
    "print(\"Starting subexperiment 2 analysis:\")\n",
    "#Get as close to just the signal (don't want noise)    \n",
    "new_t2, new_acc2 = calculate_new_range(time_array2, acc_array2, 1200, 2400)    \n",
    "new_t2, new_dacc2 = calculate_new_range(time_array2, dacc_array2, 1200, 2400)\n",
    "disp_butter_integral2 = double_integral_bandpass(new_t2, new_acc2, new_dacc2, lowcut, highcut, fs, order)\n",
    "print(\"Done.\")\n",
    "\n",
    "## For subexperiment3:\n",
    "print(\"Starting subexperiment 3 analysis:\")\n",
    "new_t3, new_acc3 = calculate_new_range(time_array3, acc_array3, 2400, 3600)    \n",
    "new_t3, new_dacc3 = calculate_new_range(time_array3, dacc_array3, 2400, 3600)\n",
    "disp_butter_integral3 = double_integral_bandpass(new_t3, new_acc3, new_dacc3, lowcut, highcut, fs, order)\n",
    "\n",
    "\n",
    "## Using butterworth filter bc it is designed to have a flat frequency response, i.e. most accurately reproducing input through output.\n",
    "\n",
    "print(\"Using butterworth filter bc it is designed to have a flat frequency response, i.e. most accurately reproducing input through output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Picking Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, find peaks and valleys of the waveforms:\n",
    "#(Found that this works better when the data has been detrended.)\n",
    "\n",
    "#Need to convert to numpy array types: \n",
    "new_dacc1 = np.array(new_dacc1)\n",
    "new_dacc2 = np.array(new_dacc2)\n",
    "new_dacc3 = np.array(new_dacc3)\n",
    "\n",
    "new_t1 = np.array(new_t1)\n",
    "new_t2 = np.array(new_t2)\n",
    "new_t3 = np.array(new_t3)\n",
    "\n",
    "\n",
    "indexes0 = peakutils.indexes(new_dacc1, thres=0.02/max(new_dacc1), min_dist=100)\n",
    "indexes1 = peakutils.indexes(new_dacc2, thres=0.02/max(new_dacc2), min_dist=100)\n",
    "indexes2 = peakutils.indexes(new_dacc3, thres=0.02/max(new_dacc3), min_dist=100)\n",
    "\n",
    "col_0t = new_t1 # First column data\n",
    "col_0a = new_dacc1 # Second column data\n",
    "\n",
    "col_1t = new_t2 # First column data\n",
    "col_1a = new_dacc2 # Second column data\n",
    "\n",
    "col_2t = new_t3 # First column data\n",
    "col_2a = new_dacc3 # Second column data\n",
    "\n",
    "\n",
    "\n",
    "#Index1 gets the peaks, while index2 gets the valleys\n",
    "index_max0 = peakutils.indexes(col_0a, thres=0.66, min_dist=25)\n",
    "index_min0 = peakutils.indexes(-col_0a, thres=0.66, min_dist=25)\n",
    "\n",
    "index_max1 = peakutils.indexes(col_1a, thres=0.66, min_dist=25)\n",
    "index_min1 = peakutils.indexes(-col_1a, thres=0.66, min_dist=25)\n",
    "\n",
    "index_max2 = peakutils.indexes(col_2a, thres=0.66, min_dist=25)\n",
    "index_min2 = peakutils.indexes(-col_2a, thres=0.66, min_dist=25)\n",
    "\n",
    "\n",
    "\n",
    "##Plotting:\n",
    "f1 = plt.figure(figsize=(12,5))\n",
    "ax1 = f1.add_subplot(121)\n",
    "ax2 = f1.add_subplot(122)\n",
    "\n",
    "f2 = plt.figure(figsize=(12,5))\n",
    "ax3 = f2.add_subplot(121)\n",
    "\n",
    "\n",
    "ax1.plot(col_0t,col_0a, lw=0.4, alpha=0.2, color=\"black\" )\n",
    "ax1.plot(col_0t[index_max0],col_0a[index_max0], marker=\"o\", ls=\"\", ms=3, color=\"red\" )\n",
    "ax1.plot(col_0t[index_min0],col_0a[index_min0], color =\"orange\", marker=\"o\", ls=\"\", ms=3 )\n",
    "ax1.set_title(\"Displacement vs. Time\")\n",
    "ax1.set_xlabel(\"Time [s]\")\n",
    "ax1.set_ylabel('Displacement [m]')\n",
    "\n",
    "\n",
    "ax2.plot(col_1t,col_1a, lw=0.4, alpha=0.2, color=\"black\" )\n",
    "ax2.plot(col_1t[index_max1],col_1a[index_max1], marker=\"o\", ls=\"\", ms=3,  color=\"red\" )\n",
    "ax2.plot(col_1t[index_min1],col_1a[index_min1], color =\"orange\", marker=\"o\", ls=\"\", ms=3 )\n",
    "ax2.set_title(\"Displacement vs. Time\")\n",
    "ax2.set_xlabel(\"Time [s]\")\n",
    "ax2.set_ylabel(\"Discplacement [m]\")\n",
    "\n",
    "\n",
    "ax3.plot(col_2t,col_2a, lw=0.4, alpha=0.2, color=\"black\" )\n",
    "ax3.plot(col_2t[index_max2],col_2a[index_max2], marker=\"o\", ls=\"\", ms=3,  color=\"red\" )\n",
    "ax3.plot(col_2t[index_min2],col_2a[index_min2], color =\"orange\", marker=\"o\", ls=\"\", ms=3 )\n",
    "ax3.set_title(\"Discplacement vs. Time\")\n",
    "ax3.set_xlabel(\"Time [s]\")\n",
    "ax3.set_ylabel(\"Displacement [m]\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the tallest 1/3 of waves to observe, then take the mean of that subset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(new_dacc1))\n",
    "print(new_dacc1[:20])\n",
    "n = int(len(new_dacc1)/3)\n",
    "print(n)\n",
    "x0 = new_dacc1\n",
    "#print (x0[np.argsort(x0)[-n:]])\n",
    "largest_third = (x0[np.argsort(x0)[-n:]])\n",
    "\n",
    "print(np.mean(largest_third))\n",
    "wave_height = np.mean(largest_third)\n",
    "print(\"Significant wave height calculated as: \", wave_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index_max0))\n",
    "n = int(len(index_max0)/3)\n",
    "print(n)\n",
    "\n",
    "max_dacc = []\n",
    "for i in range(0,len(index_max0)):\n",
    "    max_dacc.append(new_dacc1[index_max0])\n",
    "\n",
    "max_dacc = np.array(max_dacc)\n",
    "largest_third = (max_dacc[np.argsort(max_dacc)[-n:]])\n",
    "\n",
    "\n",
    "print(\"Significant wave height calculated as: \", 2*np.mean(largest_third))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrend on entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_array = acc_list = imu2_array = imu_array2\n",
    "\n",
    "dacc_test_array = signal.detrend(acc_array)\n",
    "\n",
    "butter_t_lfilter = butter_bandpass_lfilter(dacc_test_array, lowcut, highcut, fs, order=5)\n",
    "butter_t_filtfilt = butter_bandpass_filtfilt(dacc_test_array, lowcut, highcut, fs, order=5)\n",
    "\n",
    "##For entire data:\n",
    "print(\"Starting full data set analysis:\")\n",
    "#Get as close to just the signal (don't want noise)    \n",
    "new_t_test, new_acc_test = calculate_new_range(time_array, acc_array, 0, 1800)\n",
    "new_t_test, new_dacc_test = calculate_new_range(time_array, dacc_test_array, 0, 1800)\n",
    "disp_butter_integral_t = double_integral_bandpass(new_t_test, new_acc_test, new_dacc_test, lowcut, highcut, fs, order)\n",
    "print(\"Done.\")\n",
    "\n",
    "new_dacc = np.array(new_dacc_test)\n",
    "new_t = np.array(new_t_test)\n",
    "\n",
    "indices = peakutils.indexes(new_dacc, thres=0.02/max(new_dacc), min_dist=100)\n",
    "\n",
    "col_t = new_t\n",
    "col_a = new_dacc\n",
    "\n",
    "index_max = peakutils.indexes(col_a, thres=0.66, min_dist=25)\n",
    "index_min = peakutils.indexes(-col_a, thres=0.66, min_dist=25)\n",
    "\n",
    "f0 = plt.figure(figsize=(12,5))\n",
    "ax0 = f0.add_subplot(121)\n",
    "\n",
    "ax0.plot(col_t, col_a, lw=0.4, alpha=0.2, color=\"black\" )\n",
    "ax0.plot(col_t[index_max], col_a[index_max], marker=\"o\", ls=\"\", ms=3, color=\"red\" )\n",
    "ax0.plot(col_t[index_min], col_a[index_min], color =\"orange\", marker=\"o\", ls=\"\", ms=3 )\n",
    "ax0.set_title(\"Displacement vs. Time\")\n",
    "ax0.set_xlabel(\"Time [s]\")\n",
    "ax0.set_ylabel('Displacement [m]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(new_dacc)/4)\n",
    "xn = new_dacc\n",
    "upper_half = (xn[np.argsort(xn)[(2*n):(3*n)]])\n",
    "\n",
    "wave_height = 2*np.mean(upper_half)\n",
    "print(\"Significant wave height calculated as: \", wave_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = int(len(new_dacc)/3)\n",
    "xn = new_dacc\n",
    "largest_third = (xn[np.argsort(xn)[-n:]])\n",
    "\n",
    "wave_height = np.mean(largest_third)\n",
    "print(\"Significant wave height calculated as: \", wave_height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
