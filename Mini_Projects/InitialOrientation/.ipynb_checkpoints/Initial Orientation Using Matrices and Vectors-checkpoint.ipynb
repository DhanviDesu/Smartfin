{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\QM\\\\Anaconda3\\\\pkgs\\\\proj4-5.2.0-ha925a31_1\\\\Library\\\\share/epsg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43b2fdb1037c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m# create dictionary that maps epsg codes to Basemap kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mpyproj_datadir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PROJ_LIB'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mepsgf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyproj_datadir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'epsg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0mepsg_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsgf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\QM\\\\Anaconda3\\\\pkgs\\\\proj4-5.2.0-ha925a31_1\\\\Library\\\\share/epsg'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PROJ_LIB'] = r'C:\\Users\\QM\\Anaconda3\\pkgs\\proj4-5.2.0-ha925a31_1\\Library\\share'\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import constants\n",
    "from scipy import signal #added\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import simps\n",
    "from scipy.integrate import cumtrapz\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "import peakutils\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import requests\n",
    "\n",
    "import mpld3\n",
    "import folium\n",
    "#import cmocean\n",
    "import skinematics as skin\n",
    "from skinematics import quat, vector, misc, rotmat, imus, view\n",
    "import pygame\n",
    "\n",
    "from plotly import tools #added all the plotly's\n",
    "import plotly.offline\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import math #added\n",
    "import re   #added\n",
    "\n",
    "# For the definition of the abstract base class IMU_Base\n",
    "import abc\n",
    "\n",
    "import sys\n",
    "\n",
    "#%matplotlib qt\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "#import cmocean\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_ids = ['16090']\n",
    "# 13735 - One of Phil's Smartfin Surf Session Rides\n",
    "# 14743 - Motion Control July 10th\n",
    "# 14750 - Magnetometer Control July 11th\n",
    "# 14814 - Pool Displacement Control July 17th\n",
    "# 14815 - Compass Orientation (Lying on Charger Side) July 19th (4Hz data at MESOM Lab)\n",
    "# 14816 - Compass Orientation (Lying with LED down) July 20th (30Hz data at CSE UCSD)\n",
    "# 14827 - Pool Displacement Control July 23rd (30Hz at CSE UCSD)\n",
    "# 14840 - MESOM Parking Lot Static Rotation Combined Tracking (30Hz)\n",
    "# 14865 - Martz Lab Rotation Vertical Component Manual Test (30Hz)\n",
    "# 14888 - CDIP Buoy Calibration Run #1 July 30 (Fin in vertical position, pointing upwards)\n",
    "# 14893 and 14894 - Junk files to drain battery (stationary tests an hour long at constant 30Hz)\n",
    "# 14902 - Junk data when fin accidentally turn on while walking to beach for magneto calibration\n",
    "# 14903 - Beach magnetometer calibration (y-x plane (horizontal or yaw) rotation of surfboard frame) August 3rd\n",
    "# 14904 - Beach magnetometer calibration (x-z plane (lengthwise or pitch) rotation of surfboard frame) August 3rd\n",
    "# 14905 - Beach magnetometer calibration (y-z plane (crosswise or roll) rotation of surfboard frame) August 3rd\n",
    "# 15138 - First Ocean Data Experiment \"Sitting\" (August 20)\n",
    "# 16083 - Floating Next to CDIP Buoy (May 15)\n",
    "# 16090 - Orientation Calibration Sitting Outside CSE Building (May 21)\n",
    "# 16317\n",
    "print(\"Ride\",ride_ids,\"loaded up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Fin ID scraper\n",
    "# Input fin ID, get all ride IDs\n",
    "# base URL to which we'll append given fin IDs\n",
    "fin_url_base = 'http://surf.smartfin.org/fin/'\n",
    "\n",
    "# Look for the following text in the HTML contents in fcn below\n",
    "str_id_ride = 'rideId = \\'' # backslash allows us to look for single quote\n",
    "str_id_date = 'var date = \\'' # backslash allows us to look for single quote\n",
    "\n",
    "#%% Ride ID scraper\n",
    "# Input ride ID, get ocean and motion CSVs\n",
    "# Base URL to which we'll append given ride IDs\n",
    "ride_url_base = 'https://surf.smartfin.org/ride/'\n",
    "\n",
    "# Look for the following text in the HTML contents in fcn below\n",
    "str_id_csv = 'img id=\"temperatureChart\" class=\"chart\" src=\"' \n",
    "\n",
    "def get_csv_from_ride_id(rid):\n",
    "    # Build URL for each individual ride\n",
    "    ride_url = ride_url_base+str(rid)\n",
    "    print(ride_url)\n",
    "    \n",
    "    # Get contents of ride_url\n",
    "    html_contents = requests.get(ride_url).text\n",
    "    \n",
    "    # Find CSV identifier \n",
    "    loc_csv_id = html_contents.find(str_id_csv)\n",
    "    \n",
    "    # Different based on whether user logged in with FB or Google\n",
    "    offset_googleOAuth = [46, 114]\n",
    "    offset_facebkOAuth = [46, 112]\n",
    "    if html_contents[loc_csv_id+59] == 'f': # Facebook login\n",
    "        off0 = offset_facebkOAuth[0]\n",
    "        off1 = offset_facebkOAuth[1]\n",
    "    else: # Google login\n",
    "        off0 = offset_googleOAuth[0]\n",
    "        off1 = offset_googleOAuth[1]\n",
    "        \n",
    "    csv_id_longstr = html_contents[loc_csv_id+off0:loc_csv_id+off1]\n",
    "    \n",
    "#    print(csv_id_longstr)\n",
    "    \n",
    "    # Stitch together full URL for CSV\n",
    "    if (\"media\" in csv_id_longstr) & (\"Calibration\" not in html_contents): # other junk URLs can exist and break everything\n",
    "        \n",
    "        ocean_csv_url = 'https://surf.smartfin.org/'+csv_id_longstr+'Ocean.CSV'\n",
    "        motion_csv_url = 'https://surf.smartfin.org/'+csv_id_longstr+'Motion.CSV'\n",
    "        \n",
    "        print(ocean_csv_url)\n",
    "        # Go to ocean_csv_url and grab contents (theoretically, a CSV)\n",
    "        ocean_df_small = pd.read_csv(ocean_csv_url, parse_dates = [0])\n",
    "        elapsed_timedelta = (ocean_df_small['UTC']-ocean_df_small['UTC'][0])\n",
    "        ocean_df_small['elapsed'] = elapsed_timedelta/np.timedelta64(1, 's')\n",
    "        \n",
    "        motion_df_small = pd.read_csv(motion_csv_url, parse_dates = [0])\n",
    "        \n",
    "        # Reindex on timestamp if there are at least a few rows\n",
    "        if len(ocean_df_small) > 1:\n",
    "            ocean_df_small.set_index('UTC', drop = True, append = False, inplace = True)\n",
    "            motion_df_small.set_index('UTC', drop = True, append = False, inplace = True)\n",
    "            \n",
    "            print(ocean_df_small)\n",
    "            \n",
    "            \n",
    "            #May need to change this sampling interval:\n",
    "            sample_interval = '33ms'\n",
    "            \n",
    "            \n",
    "            ocean_df_small_resample = ocean_df_small.resample(sample_interval).mean()\n",
    "            motion_df_small_resample = motion_df_small.resample(sample_interval).mean()\n",
    "            \n",
    "            # No need to save many extra rows with no fix\n",
    "            motion_df_small = motion_df_small[~np.isnan(motion_df_small.Latitude)]\n",
    "            \n",
    "            return ocean_df_small_resample, motion_df_small_resample\n",
    "\n",
    "    else:\n",
    "        ocean_df_small_resample = pd.DataFrame() # empty DF just so something is returned\n",
    "        motion_df_small_resample = pd.DataFrame() \n",
    "        return ocean_df_small_resample, motion_df_small_resample\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_ocean_list = [] # list of DataFrames from original CSVs\n",
    "appended_motion_list = []\n",
    "appended_multiIndex = [] # fin_id & ride_id used to identify each DataFrame\n",
    "\n",
    "## Nested loops (for each fin ID, find all ride IDs, then build a DataFrame from all ride CSVs)\n",
    "## (Here, ride IDS are either ocean or motion dataframes)\n",
    "count_good_fins = 0\n",
    "    \n",
    "# Loop over ride_ids and find CSVs\n",
    "for rid in ride_ids:\n",
    "    try:\n",
    "        new_ocean_df, new_motion_df = get_csv_from_ride_id(rid) # get given ride's CSV from its ride ID using function above\n",
    "        #print(len(new_ocean_df))\n",
    "        #print(len(new_motion_df))\n",
    "        if not new_ocean_df.empty: # Calibration rides, for example\n",
    "            # Append only if DF isn't empty. There may be a better way to control empty DFs which are created above\n",
    "            appended_multiIndex.append(str(rid)) # build list to be multiIndex of future DataFrame\n",
    "            appended_ocean_list.append(new_ocean_df)\n",
    "            appended_motion_list.append(new_motion_df)\n",
    "            print(\"Ride data has been uploaded.\")\n",
    "            #print(\"Ride: \", rid, \"data has been uploaded.\")\n",
    "            count_good_fins += 1\n",
    "        \n",
    "    except: \n",
    "        print(\"Ride threw an exception!\")\n",
    "        #print(\"Ride \", rid, \"threw an exception!\")    \n",
    "\n",
    "#%% Build the \"Master\" DataFrame\n",
    "\n",
    "# appended_ocean_df.summary()\n",
    "df_keys = tuple(appended_multiIndex) # keys gotta be a tuple, a list which data in it cannot be changed\n",
    "ocean_df = pd.concat(appended_ocean_list, keys = df_keys, names=['ride_id'])\n",
    "motion_df = pd.concat(appended_motion_list, keys = df_keys, names = ['ride_id'])\n",
    "\n",
    "\n",
    "##Here, maybe just use info from the motion_df and don't worry about ocean_df data for now.\n",
    "##If you do want ocean_df data, look at how Phil was getting it from \"July 10th and 11th Calibration\" jupyter notebook file.\n",
    "#print(motion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(motion_df)\n",
    "\n",
    "saved_copy_motion_df = motion_df.copy(deep=True) #make a copy of the dataframe with raw data\n",
    "\n",
    "print(saved_copy_motion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from ride_ids = ['xxxxx']\n",
    "#The name of the motion dataframe is: motion_df\n",
    "\n",
    "#Get times from the \"Time\" column to create time_o_list and time_e_list.\n",
    "#Get imus from the \"IMU A[*]\" column to create the imu acc arrays. \n",
    "\n",
    "#Drop the \"nan\" values from the columns that we care about. \n",
    "dropped_motion_df = motion_df.dropna(subset=['Time', 'IMU A1', 'IMU A2', 'IMU A3', 'IMU G1', 'IMU G2', 'IMU G3', 'IMU M1', \n",
    "                                            'IMU M2', 'IMU M3'])\n",
    "#Can test that this works by printing this one:\n",
    "#dropped_motion_df = motion_df.dropna(subset=['Time', 'IMU A1', 'IMU A2', 'IMU A3', 'Latitude'])\n",
    "#print(dropped_df)\n",
    "\n",
    "time_e_list = []\n",
    "time_o_list = []\n",
    "\n",
    "#Remove all nan instances in time:\n",
    "time_array_nans = np.array(dropped_motion_df.loc[:,\"Time\"], dtype=float)\n",
    "time_array = []\n",
    "imuA1_array_nans = np.array(dropped_motion_df.loc[:,\"IMU A1\"], dtype=float)\n",
    "imu_array_A1 = []\n",
    "imuA2_array_nans = np.array(dropped_motion_df.loc[:,\"IMU A2\"], dtype=float)\n",
    "imu_array_A2 = []\n",
    "imuA3_array_nans = np.array(dropped_motion_df.loc[:,\"IMU A3\"], dtype=float)\n",
    "imu_array_A3 = []\n",
    "imuG1_array_nans = np.array(dropped_motion_df.loc[:,\"IMU G1\"], dtype=float)\n",
    "imu_array_G1 = []\n",
    "imuG2_array_nans = np.array(dropped_motion_df.loc[:,\"IMU G2\"], dtype=float)\n",
    "imu_array_G2 = []\n",
    "imuG3_array_nans = np.array(dropped_motion_df.loc[:,\"IMU G3\"], dtype=float)\n",
    "imu_array_G3 = []\n",
    "imuM1_array_nans = np.array(dropped_motion_df.loc[:,\"IMU M1\"], dtype=float)\n",
    "imu_array_M1 = []\n",
    "imuM2_array_nans = np.array(dropped_motion_df.loc[:,\"IMU M2\"], dtype=float)\n",
    "imu_array_M2 = []\n",
    "imuM3_array_nans = np.array(dropped_motion_df.loc[:,\"IMU M3\"], dtype=float)\n",
    "imu_array_M3 = []\n",
    "\n",
    "#Get all the times and imus where time, imu a1, imu a2, and imu a3 are NOT nan values:\n",
    "for t,x,y,z,a,b,c,d,e,f in zip(time_array_nans, imuA1_array_nans, imuA2_array_nans, imuA3_array_nans, imuG1_array_nans, \n",
    "                              imuG2_array_nans, imuG3_array_nans, imuM1_array_nans, imuM2_array_nans, imuM3_array_nans):\n",
    "    if (np.isnan(t)==0 and np.isnan(x)==0 and np.isnan(y)==0 and np.isnan(z)==0):\n",
    "        time_array.append(t)\n",
    "        imu_array_A1.append(x)\n",
    "        imu_array_A2.append(y)\n",
    "        imu_array_A3.append(z)\n",
    "        imu_array_G1.append(a)\n",
    "        imu_array_G2.append(b)\n",
    "        imu_array_G3.append(c)\n",
    "        imu_array_M1.append(d)\n",
    "        imu_array_M2.append(e)\n",
    "        imu_array_M3.append(f)\n",
    "\n",
    "#for x in time_array:\n",
    "#    print(x)\n",
    "    \n",
    "start_time = time_array[0]\n",
    "time_len = len(time_array)\n",
    "    \n",
    "i = 0\n",
    "while (i < time_len - 1):\n",
    "    prev = time_array[i]\n",
    "    after = time_array[i+1]\n",
    "    offset = after - prev\n",
    "    #if (np.isnan(offset)==0):\n",
    "    time_o_list.append(offset)\n",
    "    \n",
    "    elapsed = time_array[i] - start_time\n",
    "    #if (np.isnan(elapsed)==0):\n",
    "    time_e_list.append(elapsed)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "##Check to make sure there are no \"nan\" values:\n",
    "i = 0\n",
    "while (i < len(time_o_list)):\n",
    "    if (np.isnan(time_o_list[i])):\n",
    "        print(\"Error! Value at index: \", i, \" is nan\")\n",
    "    i = i + 1\n",
    "\n",
    "#Drop the last value from each of the imu lists to make it match the time list.\n",
    "del(imu_array_A1[-1])\n",
    "del(imu_array_A2[-1])\n",
    "del(imu_array_A3[-1])\n",
    "del(imu_array_G1[-1])\n",
    "del(imu_array_G2[-1])\n",
    "del(imu_array_G3[-1])\n",
    "del(imu_array_M1[-1])\n",
    "del(imu_array_M2[-1])\n",
    "del(imu_array_M3[-1])\n",
    "    \n",
    "#print(len(time_e_list))\n",
    "#print(len(time_o_list))\n",
    "#print(len(imu_array_A1))\n",
    "#print(len(imu_array_A2))\n",
    "#print(len(imu_array_A3))\n",
    "#print(len(imu_array_G1))\n",
    "#print(len(imu_array_G2))\n",
    "#print(len(imu_array_G3))\n",
    "#print(len(imu_array_M1))\n",
    "#print(len(imu_array_M2))\n",
    "#print(len(imu_array_M3))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert raw units to actual units (acc to [m/s^2]) and (time to [s])\n",
    "#Raw acceleration constant 512 = 1g (accelerometer's measured force due to gravity)\n",
    "g_const = 512\n",
    "gyro_const = 8.2      # Raw gyrscope constant 8.2 bits per degree\n",
    "\n",
    "gravity = 9.80665     # Approximate measurement for gravity\n",
    "\n",
    "# Correct the IMU Acceleration columns into units of meters\n",
    "# Dividing by 512 is equivalent to muliplying by 4 to correct the bit shifting by 2 places and dividing by 2048 to convert bits to G's\n",
    "# Multiplying by the 9.81 afterwards is simply to convert G's into m/s^2\n",
    "\n",
    "def convert_acc_units(acc_array):\n",
    "    ret_array = []\n",
    "    for a in acc_array:\n",
    "        #Acceleration is now in m/s^2, need to subtract gravity from vertical axis. (??) --> Not yet, we'll do it later on\n",
    "        new_a = a / g_const * gravity# - gravity\n",
    "        ret_array.append(new_a)\n",
    "    return ret_array\n",
    "\n",
    "imuA1_array = convert_acc_units(imu_array_A1) #new units in m/s^2\n",
    "imuA2_array = convert_acc_units(imu_array_A2) #new units in m/s^2\n",
    "imuA3_array = convert_acc_units(imu_array_A3) #new units in m/s^2\n",
    "\n",
    "##To check:\n",
    "#for x,y in zip(imuA2_array, imu_array_A2):\n",
    "    #print(x,y)\n",
    "    \n",
    "def convert_gyr_units(gyr_array):\n",
    "    ret_array = []\n",
    "    for g in gyr_array:\n",
    "        # Gyroscopic Rotation converts to deg/s\n",
    "        new_g = g / gyro_const\n",
    "        ret_array.append(new_g)\n",
    "    return ret_array\n",
    "\n",
    "imuG1_array_not_cal = convert_gyr_units(imu_array_G1) #new units in deg/s (will need to be rads for some later functions)\n",
    "imuG2_array_not_cal = convert_gyr_units(imu_array_G2)\n",
    "imuG3_array_not_cal = convert_gyr_units(imu_array_G3)\n",
    "\n",
    "#To check:\n",
    "#for x,y in zip(imuG2_array, imu_array_G2):\n",
    "    #print(x,y)\n",
    "    \n",
    "    \n",
    "def convert_time_units(time_array):\n",
    "    ret_array = []\n",
    "    for t in time_array:\n",
    "        new_t = t * (10**(-3)) #converting units in milliseconds to seconds\n",
    "        ret_array.append(new_t)\n",
    "    return ret_array\n",
    "\n",
    "time_o_array = convert_time_units(time_o_list) #new units in seconds\n",
    "time_e_array = convert_time_units(time_e_list) #new units in seconds\n",
    "\n",
    "##To check:\n",
    "#for t in time_e_array:\n",
    "#    print(t)\n",
    "\n",
    "print(len(time_e_array))\n",
    "print(len(time_e_list))\n",
    "print(len(imuA2_array))\n",
    "\n",
    "#print(imuA1_array)\n",
    "#print(rotmat.R(imuA1_array, ___))\n",
    "\n",
    "plt.plot(time_e_array, imuA1_array)\n",
    "plt.show()\n",
    "plt.plot(time_e_array, imuA2_array)\n",
    "plt.show()\n",
    "plt.plot(time_e_array, imuA3_array)\n",
    "plt.show()\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG2_array)\n",
    "#plt.show()\n",
    "\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG1_array_not_cal)\n",
    "#plt.show()\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG1_array)\n",
    "#plt.show()\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG2_array_not_cal)\n",
    "#plt.show()\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG2_array)\n",
    "#plt.show()\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG3_array_not_cal)\n",
    "#plt.show()\n",
    "#print(\"Gyro_plot:\")\n",
    "#plt.plot(time_e_array, imuG3_array)\n",
    "#plt.show()\n",
    "\n",
    "#print(\"Why are the y-axis values so small?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_gyroscope_calibration(gyr, thresh):\n",
    "    # Takes in gyroscope array [1xN] and a threshold value in deg/s\n",
    "    print(\"The current threshold value is:\",thresh)       # Prints the threshold\n",
    "    ret_array = gyr.copy()                            # Initialize the calibrated return array (which will be calibrated and returned)\n",
    "    calibration_constant = 0                              # Initialize loop variables\n",
    "    last_touched_value = 0\n",
    "    calibration_was_attempted = 0\n",
    "    current = 0\n",
    "    #calibrations_completed = 0\n",
    "    calarray_pos = np.zeros(shape=(500,1))                  #Initialize an array to store calibration constant positions in (made excessively large for longer sessions)\n",
    "    calarray_constants = np.zeros(shape=(500,1))            #Initialize an array to store calibration constant values\n",
    "    print(\"Total rows of data:\", len(gyr))\n",
    "    \n",
    "    calibration_was_attempted = 0     # Reset all state variables\n",
    "    last_touched_value = 0\n",
    "    calibrations_completed = 0\n",
    "    current = 0                       # Reset iterator\n",
    "    while current < len(gyr) - 100:\n",
    "    #for current in range(len(gyr)):\n",
    "        calibration_was_attempted = 0                 #Reset the state of calibration attempted\n",
    "        curr_pos = gyr[current]\n",
    "        next_pos = gyr[current+1]\n",
    "        difference = next_pos - curr_pos          #Find the delta between current and next value\n",
    "        \n",
    "        if (difference < thresh) and (difference > -1*thresh):   #If the delta is within the threshold:\n",
    "            calibration_was_attempted = 1                        #Change state: calibration_was_attempted to true\n",
    "            start_average = current                              #Mark the start of a potential averaging window\n",
    "            end_average = current+1                              #Initialize the end of a potential averaging window (size 1 to be safe)\n",
    "            next_seven_fail = 0                                  #Initialize variable to tell if next 7 deltas were within threshold\n",
    "            end_of_deltas = 0                                    #Initialize variable to tell when delta is no longer within threshold\n",
    "            final_sev_check_pos = 0                              #Initialize variable to hold marker at the last seven check position\n",
    "           \n",
    "            for seven_check in range(7):                                       # Check the next 7 deltas (1/4 second @ 30Hz) to get min window\n",
    "                sev_check_curr_pos = gyr[current+seven_check+1]\n",
    "                sev_check_next_pos = gyr[current+seven_check+2]\n",
    "                sev_check_difference = sev_check_next_pos - sev_check_curr_pos\n",
    "                if (sev_check_difference > thresh) or (sev_check_difference < -1*thresh):  # If at any point a delta is not within threshold, then stop and start over\n",
    "                    next_seven_fail = 1                         #Change failure status of seven_check to TRUE\n",
    "                    final_sev_check_pos = current+seven_check+1\n",
    "                    last_touched_value = current+seven_check+1  #Update the last_touched_value by the loop\n",
    "                    break                                       #Break out of the loop and restart\n",
    "                final_sev_check_pos = current+seven_check+1     #Update the last position in seven_check\n",
    "                end_average = final_sev_check_pos               #Update the end of the averaging window\n",
    "                last_touched_value = end_average                #Update the last touched value\n",
    "            \n",
    "            if next_seven_fail == 0:                      #If the next seven deltas are within threshold, continue looking for last valid delta (if seven_check failed, then this loop shouldn't run)\n",
    "                iterator = 0\n",
    "                while (end_of_deltas == 0) and (not (gyr[final_sev_check_pos+iterator] is None)):\n",
    "                    #while we haven't found the last valid delta, AND the next value isn't empty/DNE\n",
    "                    if final_sev_check_pos+iterator+1 >= len(gyr):\n",
    "                        end_of_deltas = 1\n",
    "                        end_average = final_sev_check_pos+iterator\n",
    "                        last_touched_value = end_average\n",
    "                    else:\n",
    "                        finding_end_curr_pos = gyr[final_sev_check_pos+iterator]\n",
    "                        finding_end_next_pos = gyr[final_sev_check_pos+iterator+1]\n",
    "                        finding_end_difference = finding_end_next_pos - finding_end_curr_pos\n",
    "                        if (finding_end_difference >= thresh) or (finding_end_difference <= -1*thresh):      #if difference is outside threshold, enter \"end found\" state\n",
    "                            end_of_deltas = 1                                     #Set \"end found\" state to true\n",
    "                            end_average = final_sev_check_pos+iterator            #Mark ending of window with the last valid delta position\n",
    "                            last_touched_value = end_average                      #Update the last touched value\n",
    "                            break\n",
    "                        iterator += 1\n",
    "                averaging_pos = start_average\n",
    "                total_sum = 0\n",
    "                num_of_nums = 0\n",
    "                while (averaging_pos < end_average) and (averaging_pos < len(gyr)-1):\t#Start averaging the values within the averaging window\n",
    "                    total_sum += gyr[averaging_pos]\n",
    "                    num_of_nums += 1\n",
    "                    averaging_pos += 1\n",
    "                calibration_constant = total_sum / num_of_nums\n",
    "                calarray_pos[calibrations_completed] = current #Store calibration start location into an array\n",
    "                calarray_constants[calibrations_completed] = calibration_constant #Store calibrations into an array\n",
    "                calibrations_completed += 1\n",
    "                #print(\"Start of the average was\",start_average)\n",
    "                #print(\"Position of the last touched value was\",last_touched_value)\n",
    "                #print(\"Newest calibration calculated:\",calibration_constant)\n",
    "        if calibration_was_attempted == 1:\n",
    "            current = last_touched_value     #Assign current to the last value looked at by the loop, to avoid redundant searches\n",
    "        else:\n",
    "            current += 1\n",
    "    \n",
    "    cal_pos_iterator = 0     # Iterator to point to next upcoming calibration position, so we know when to change calibration value\n",
    "    for i in range(len(ret_array)):\n",
    "        if cal_pos_iterator == 0:     # Unique case for setting the first calibration constant\n",
    "            enforcer = calarray_constants[0]\n",
    "            cal_pos_iterator = 1\n",
    "            #cal_value_iterator = 1\n",
    "            ret_array[i] -= enforcer\n",
    "        else:\n",
    "            if i < calarray_pos[cal_pos_iterator] and i < len(ret_array)-1:       # if the current position hasn't reached the start of the next calibration window\n",
    "                ret_array[i] -= enforcer\n",
    "            elif i == calarray_pos[cal_pos_iterator] and i < len(ret_array)-1:    # if the current position is at the start of the next calibration window\n",
    "                enforcer = calarray_constants[cal_pos_iterator]\n",
    "                cal_pos_iterator += 1\n",
    "                ret_array[i] -= enforcer\n",
    "            elif i > calarray_pos[cal_pos_iterator] and i < len(ret_array)-1 and calarray_pos[cal_pos_iterator] == 0:\n",
    "                ret_array[i] -= enforcer\n",
    "            else:\n",
    "                print(\"Current position skipped unexpectedly past next calibration window.\")\n",
    "                print(i)\n",
    "                break\n",
    "    return ret_array\n",
    "\n",
    "\n",
    "threshold = 5 / 8.2  # Set the threshold that passes to the calibration function\n",
    "imuG1_array = adaptive_gyroscope_calibration(imuG1_array_not_cal, threshold)\n",
    "imuG2_array = adaptive_gyroscope_calibration(imuG2_array_not_cal, threshold)\n",
    "imuG3_array = adaptive_gyroscope_calibration(imuG3_array_not_cal, threshold)\n",
    "\n",
    "G1_comparison = np.stack((imuG1_array_not_cal, imuG1_array), axis=-1)\n",
    "print(G1_comparison)\n",
    "print(\"Done calibrating.\")\n",
    "\n",
    "print(\"Gyro_plot:\")\n",
    "plt.plot(time_e_array, imuG1_array)\n",
    "plt.show()\n",
    "print(\"Gyro_plot:\")\n",
    "plt.plot(time_e_array, imuG2_array)\n",
    "plt.show()\n",
    "print(\"Gyro_plot:\")\n",
    "plt.plot(time_e_array, imuG3_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset variables help in recentering the magnetic data in order to define direction and use trig functions\n",
    "#     for some calculations. These values were estimated from data collected from multiple tests and hold fairly well.\n",
    "# Magnetic data is relative, so as long as all of the axis share similar magnitude in value, then data should be fine\n",
    "M1_offset_var = 219.786\n",
    "M2_offset_var = 180\n",
    "M3_offset_var = 280\n",
    "\n",
    "def calibrate_magn_data(magn_array, offset_value):\n",
    "    ret_array = []\n",
    "    for m in magn_array:\n",
    "        new_m = m - offset_value\n",
    "        ret_array.append(new_m)\n",
    "    return ret_array\n",
    "\n",
    "imuM1_array = calibrate_magn_data(imu_array_M1, M1_offset_var)\n",
    "imuM2_array = calibrate_magn_data(imu_array_M2, M2_offset_var)\n",
    "imuM3_array = calibrate_magn_data(imu_array_M3, M3_offset_var)\n",
    "\n",
    "#print(imu_array_M1)\n",
    "#print(imuM1_array)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create N x 3 arrays for functions that need them later on, such as Scikit Kinematics\n",
    "acc_height = len(imuA1_array)\n",
    "print(acc_height)\n",
    "gyr_height = len(imuG1_array)\n",
    "magn_height = len(imuM1_array)\n",
    "\n",
    "acc_array = np.zeros(shape=(acc_height,3))\n",
    "gyr_array = np.zeros(shape=(gyr_height,3))\n",
    "magn_array = np.zeros(shape=(magn_height,3))\n",
    "\n",
    "for x in range(len(acc_array)):\n",
    "    acc_array[x,0] = imuA1_array[x]\n",
    "    acc_array[x,1] = imuA2_array[x]\n",
    "    acc_array[x,2] = imuA3_array[x]\n",
    "#print(acc_array)\n",
    "\n",
    "for x in range(len(gyr_array)):\n",
    "    gyr_array[x,0] = imuG1_array[x]\n",
    "    gyr_array[x,1] = imuG2_array[x]\n",
    "    gyr_array[x,2] = imuG3_array[x]\n",
    "#print(gyr_array)\n",
    "\n",
    "for x in range(len(magn_array)):\n",
    "    magn_array[x,0] = imuM1_array[x]\n",
    "    magn_array[x,1] = imuM2_array[x]\n",
    "    magn_array[x,2] = imuM3_array[x]\n",
    "#print(magn_array)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new array for board reference frame will have the IMUs in columns according to X,Y,Z directions\n",
    "board_acc = acc_array.copy()       # Reassign to the correct axes as stated above\n",
    "temp_x_acc = board_acc[:,0] * (-1)\n",
    "temp_y_acc = board_acc[:,2] * (-1)\n",
    "temp_z_acc = board_acc[:,1] * (-1)\n",
    "board_acc[:,0] = temp_x_acc     # X acceleration\n",
    "board_acc[:,1] = temp_y_acc     # Y acceleration\n",
    "board_acc[:,2] = temp_z_acc     # Z acceleration\n",
    "\n",
    "#print('X              ', 'Y              ', 'Z')\n",
    "#print(acc_array[:4,:])\n",
    "#print(board_acc[:4,:])     # Display check to see if they are properly assigned\n",
    "board_gyr = gyr_array.copy()\n",
    "temp_x_gyr = board_gyr[:,0] * (-1)\n",
    "temp_y_gyr = board_gyr[:,2] * (-1)\n",
    "temp_z_gyr = board_gyr[:,1] * (-1)\n",
    "board_gyr[:,0] = temp_x_gyr\n",
    "board_gyr[:,1] = temp_y_gyr\n",
    "board_gyr[:,2] = temp_z_gyr\n",
    "\n",
    "board_magn = magn_array.copy()\n",
    "temp_x_magn = board_magn[:,0] * (-1)\n",
    "temp_y_magn = board_magn[:,2] * (-1)\n",
    "temp_z_magn = board_magn[:,1] * (-1)\n",
    "board_magn[:,0] = temp_x_magn\n",
    "board_magn[:,1] = temp_y_magn\n",
    "board_magn[:,2] = temp_z_magn\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(board_acc)\n",
    "#print(board_gyr)\n",
    "#print(board_magn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS WHERE I DO ORIENTATION ROTATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "\n",
    "board_acc_norms = preprocessing.normalize(board_acc, norm='l2')\n",
    "board_magn_norms = preprocessing.normalize(board_magn, norm='l2')\n",
    "\n",
    "#print(board_acc[0])\n",
    "#print(board_acc_norms[0])\n",
    "gravity_vec = board_acc_norms[0]\n",
    "entry_1_1 = (math.pow(gravity_vec[1], 2) - (math.pow(gravity_vec[0], 2) * gravity_vec[2]))\n",
    "entry_1_1 /= (math.pow(gravity_vec[0], 2) + math.pow(gravity_vec[1], 2))\n",
    "entry_2_1 = (-(gravity_vec[0] * gravity_vec[1]) - (gravity_vec[0] * gravity_vec[1] * gravity_vec[2]))\n",
    "entry_2_1 /= (math.pow(gravity_vec[0], 2) + math.pow(gravity_vec[1], 2))\n",
    "entry_3_1 = -gravity_vec[0]\n",
    "first_column = np.array([entry_1_1, entry_2_1, entry_3_1])\n",
    "entry_1_2 = entry_2_1\n",
    "entry_2_2 = (math.pow(gravity_vec[0], 2) - (math.pow(gravity_vec[1], 2) * gravity_vec[2]))\n",
    "entry_2_2 /= (math.pow(gravity_vec[0], 2) + math.pow(gravity_vec[1], 2))\n",
    "entry_3_2 = -gravity_vec[1]\n",
    "second_column = np.array([entry_2_1, entry_2_2, entry_3_2])\n",
    "third_column = np.array([gravity_vec[0], gravity_vec[1], -gravity_vec[2]])\n",
    "rotation_matrix = np.column_stack((first_column, second_column, third_column))\n",
    "gravity_as_np = np.array(gravity_vec)\n",
    "gravity_after_rotation = np.matmul(rotation_matrix, np.transpose(gravity_as_np))\n",
    "print(gravity_after_rotation)\n",
    "\n",
    "ent_1_1 = 1 / (math.sqrt(1 + (math.pow(gravity_vec[1], 2) / math.pow(gravity_vec[0], 2))))\n",
    "ent_2_1 = gravity_vec[1] / (gravity_vec[0] * (math.sqrt(1 + (math.pow(gravity_vec[1], 2) / math.pow(gravity_vec[0], 2)))))\n",
    "first_col = np.array([ent_1_1, ent_2_1, 0])\n",
    "ent_1_2 = -ent_2_1\n",
    "ent_2_2 = ent_1_1\n",
    "second_col = np.array([ent_1_2, ent_2_2, 0])\n",
    "third_col = np.array([0, 0, 1])\n",
    "rot_matrix = np.column_stack((first_col, second_col, third_col))\n",
    "\n",
    "board_acc_rotation = board_acc.copy()\n",
    "for x in range(len(board_acc_rotation)):\n",
    "    board_acc_rotation[x] = np.matmul(rotation_matrix, np.transpose(board_acc_rotation[x]))\n",
    "    \n",
    "board_magn_rotation = board_magn.copy()\n",
    "for x in range(len(board_magn_rotation)):\n",
    "    board_magn_rotation[x] = np.matmul(rot_matrix, np.transpose(board_magn_rotation[x]))\n",
    "#print(board_acc_norms)\n",
    "#print(board_magn_norms)\n",
    "#north_vec = board_magn_norms[0]\n",
    "#down_vec = board_acc_norms[0]\n",
    "#east_vec = np.cross(down_vec, north_vec)\n",
    "#rotation_matrix = np.column_stack((north_vec, east_vec, down_vec))\n",
    "#print(rotation_matrix)\n",
    "#rotation_matrix = np.transpose(rotation_matrix)\n",
    "#print(rotation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will get complicated (ie make cases or lots of if statements) when rotations about the heading become more prevalent\n",
    "def azimuth(x,y,z):\n",
    "    real_y = y * (-1) # This is to account for y \n",
    "    return (180/math.pi * math.atan2(real_y,x)) % 360\n",
    "\n",
    "def altitude(x,y,z):\n",
    "    h = math.hypot(y, x)\n",
    "    return 180/math.pi * math.atan2(z,h)\n",
    "\n",
    "def printAltAzi(alt, azi):\n",
    "    print (\"Alt:\", alt, \"\\n\", \"Azi:\",azi,\"\\n\")\n",
    "# These values are uncorrected values: still need to add or subtract 'declination'\n",
    "#     (for AziMuth) and 'inclination' (for Altitude) correction values for geographical location\n",
    "# Altitude is the angle between the ground and the vector \n",
    "# Azimuth is the angle going clockwise from 0 deg North\n",
    "\n",
    "heading_altitude = board_magn[:,0].copy()\n",
    "heading_azimuth = board_magn[:,0].copy()\n",
    "\n",
    "i = 0     #iterator\n",
    "#for i in range(len(M1_no_out)):\n",
    "while i < len(heading_altitude):\n",
    "    heading_altitude[i] = altitude(board_magn[i,0], board_magn[i,1], board_magn[i,2])\n",
    "    heading_azimuth[i] = azimuth(board_magn[i,0], board_magn[i,1], board_magn[i,2])\n",
    "    #printAltAzi(heading_altitude[i],heading_azimuth[i])\n",
    "    i += 1\n",
    "\n",
    "heading_azi_plot = plt.figure(figsize=(10,5))\n",
    "azi_plot = heading_azi_plot.add_subplot(111)\n",
    "azi_plot.plot(time_e_array, heading_azimuth)\n",
    "azi_plot.set_title(\"Azimuth vs. Time\")\n",
    "azi_plot.set_xlabel(\"Time Elapsed[sec]\")\n",
    "azi_plot.set_ylabel(\"Azimuth [deg]\")\n",
    "azi_plot.set_ylim([-50,400])\n",
    "\n",
    "heading_alt_plot = plt.figure(figsize=(10,5))\n",
    "alt_plot = heading_alt_plot.add_subplot(111)\n",
    "alt_plot.plot(time_e_array, heading_altitude)\n",
    "alt_plot.set_title(\"Altitude vs. Time\")\n",
    "alt_plot.set_xlabel(\"Time Elapsed [sec]\")\n",
    "alt_plot.set_ylabel(\"Altitude [deg]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the EXACT number that is shown for declination (since yaw and azimuth opposite directions/signs)\n",
    "# Enter the EXACT number that is shown for inclination\n",
    "declination = 11.5\n",
    "inclination = 57.87\n",
    "LFF_fick_yaw = (-1)*declination\n",
    "LFF_fick_pitch = inclination\n",
    "LFF_fick_roll = 0\n",
    "\n",
    "# Convert angles entered to radians for trig functions\n",
    "Y = np.deg2rad(LFF_fick_yaw)\n",
    "P = np.deg2rad(LFF_fick_pitch)\n",
    "R = np.deg2rad(LFF_fick_roll)\n",
    "# Set up the Fick angle matrix\n",
    "c11 = np.cos(Y)*np.cos(P)\n",
    "c12 = np.cos(Y)*np.sin(P)*np.sin(R) - np.sin(Y)*np.sin(R)\n",
    "c13 = np.cos(Y)*np.sin(P)*np.cos(R) + np.sin(Y)*np.sin(R)\n",
    "c21 = np.sin(Y)*np.cos(P)\n",
    "c22 = np.sin(Y)*np.sin(P)*np.sin(R) + np.cos(Y)*np.cos(R)\n",
    "c23 = np.sin(Y)*np.sin(P)*np.cos(R) - np.cos(Y)*np.sin(R)\n",
    "c31 = (-1)*np.sin(P)\n",
    "c32 = np.cos(P)*np.sin(R)\n",
    "c33 = np.cos(P)*np.cos(R)\n",
    "\n",
    "rotmat_lff2mag = np.array([[c11, c12, c13],\n",
    "                        [c21, c22, c23],\n",
    "                        [c31, c32, c33]])\n",
    "\n",
    "print(\"rotmat_lff2mag: \\n\", rotmat_lff2mag, \"\\n\")\n",
    "lff2mag_rad = rotmat.sequence(rotmat_lff2mag, 'Fick') # Check if the matrix accurately represents the desired Fick angles\n",
    "lff2mag_deg = lff2mag_rad * 180/np.pi\n",
    "print(\"lff2mag_deg Fick Angles: \\n\", lff2mag_deg,\"\\n\")\n",
    "\n",
    "# Now find the inverse of the matrix, since we want to go from magnetic field to LFF\n",
    "#rotmat_mag2lff = np.matrix.transpose(rotmat_lff2mag)\n",
    "rotmat_mag2lff = np.linalg.inv(rotmat_lff2mag)\n",
    "print(\"rotmat_mag2lff: \\n\", rotmat_mag2lff, \"\\n\")\n",
    "mag2lff_rad = rotmat.sequence(rotmat_mag2lff, 'Fick')\n",
    "mag2lff_deg = mag2lff_rad * 180/np.pi\n",
    "print(\"mag2lff_deg Fick Angles: \\n\", mag2lff_deg, \"\\n\")\n",
    "\n",
    "print(\"Is it identity matrix?: \\n\", np.matmul(rotmat_lff2mag,rotmat_mag2lff))\n",
    "mag2lff_helm_rad = rotmat.sequence(rotmat_mag2lff, 'Helmholtz')\n",
    "mag2lff_helm_deg = mag2lff_helm_rad * 180/np.pi\n",
    "print(\"mag2lff_deg Helmholtz Angles: \\n\", mag2lff_helm_deg, \"\\n\")\n",
    "\n",
    "Q_mag2lff = rotmat.seq2quat(mag2lff_deg, 'Fick')\n",
    "print(\"Transformation Quaternion for mag2lff: \\n\", Q_mag2lff) #Print out quaternion describing the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaw rotation - convert azimuth to yaw, since they are opposites of each other in direction\n",
    "print(\"Initial Azimuth and Altitude: \\n\", heading_azimuth[0], heading_altitude[0], \"\\n\")\n",
    "init_yaw = heading_azimuth[0] * (-1)\n",
    "init_pos_first_rotation = rotmat.R('z', init_yaw)                               #print(init_pos_first_rotation, \"\\n\")\n",
    "\n",
    "rotmat_first_init_rot_rad = rotmat.sequence(init_pos_first_rotation, to='Fick')\n",
    "rotmat_first_init_rot_deg = rotmat_first_init_rot_rad * 180/np.pi               #print(rotmat_first_init_rot_deg)\n",
    "\n",
    "# Pitch rotation - convert alitude to pitch, since they are opposites of each other in direction\n",
    "init_pitch = heading_altitude[0] * (-1)\n",
    "init_pos_second_rotation = rotmat.R('y', init_pitch)                            #print(init_pos_second_rotation, \"\\n\")\n",
    "\n",
    "rotmat_second_init_rot_rad = rotmat.sequence(init_pos_second_rotation, to='Fick')\n",
    "rotmat_second_init_rot_deg = rotmat_second_init_rot_rad * 180/np.pi             #print(rotmat_second_init_rot_deg)\n",
    "\n",
    "rotmat_init_pos = np.matmul(init_pos_first_rotation, init_pos_second_rotation)  #print(rotmat_init_pos, \"\\n\")\n",
    "\n",
    "# Combine rotations into a single sequence of rotations\n",
    "Initial_Position_offset_rad = rotmat.sequence(rotmat_init_pos, to='Fick')\n",
    "Initial_Position_offset_deg = Initial_Position_offset_rad * 180/np.pi\n",
    "Q_init_pos = rotmat.seq2quat(Initial_Position_offset_deg, 'Fick')\n",
    "print(\"Initial Orientation Rotation Matrix: \\n\", rotmat_init_pos, \"\\n\")\n",
    "print(\"Initial Orientation Fick Angles: \\n\", Initial_Position_offset_deg, \"\\n\")\n",
    "print(\"Initial Orientation Quaternion: \\n\", Q_init_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the delta quaternions relative to the Earth's magnetic reference frame from the rate, accelerometer, gyro,\n",
    "#     and magnetic data. All functions automatically iterate through arrays unless specified otherwise\n",
    "rate = 33 # Frequency of data polling in Hz\n",
    "board_gyr_rad = board_gyr * np.pi/180     # Converting from degrees to radians for the kalman function to create quaternions\n",
    "delta_quats = imus.kalman(rate,board_acc_rotation,board_gyr_rad,board_magn_rotation)\n",
    "#print(len(delta_quats))\n",
    "#print(delta_quats)\n",
    "print(\"Kalman quaternions finished.\")\n",
    "\n",
    "init_rotated_quats = quat.q_mult(Q_init_pos, delta_quats) # Using delta_quats instead of vector quats to avoid unit length\n",
    "#print(init_rotated_quats, \"\\n\")\n",
    "\n",
    "#init_rotated_quats2 = quat.q_mult(delta_vectors, Q_init_pos)\n",
    "#print(init_rotated_quats2)\n",
    "print(\"Initial orientation quaternion applied to Kalman quats.\")\n",
    "\n",
    "final_orient_quats = quat.q_mult(Q_mag2lff, init_rotated_quats)\n",
    "#print(final_orient_quats) # Still delta quaternions, not absolute position/angles\n",
    "print(\"Magnetic to LFF quaternion applied to other quats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_quats = quat.q_vector(delta_quats)\n",
    "print(delta_quats)\n",
    "print(init_rotated_quats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter 2 to view geographic animation, 1 to view raw animation, otherwise set to 0 for none\n",
    "view_animation = 2\n",
    "print(len(delta_quats))\n",
    "print(np.floor(1000/60))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "if view_animation == 1:\n",
    "    #view.orientation(quat_array, out_file=None, title_text='Ride 13735 Filtered', deltaT = 1000)\n",
    "    viewer = view.Orientation_OGL(delta_quats, rate = 30) #Make the simulation run at 250ms intervals, so show \"real time\" movement\n",
    "    viewer.run(looping=False, rate=120)                     #Force the simulation to run at 4Hz to match the 250ms intervals\n",
    "    # Close the window to prevent kernel crash at the end\n",
    "    pygame.display.quit()\n",
    "    #view.ts(quat_array)\n",
    "elif view_animation == 2:\n",
    "    viewer = view.Orientation_OGL(final_orient_quats, rate == 30)\n",
    "    viewer.run(looping=False, rate = 120) # Run it at 4 times speed to speed things up\n",
    "    pygame.display.quit()\n",
    "print(\"All Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
