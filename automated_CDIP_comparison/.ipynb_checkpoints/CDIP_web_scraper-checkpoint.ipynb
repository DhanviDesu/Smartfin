{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDIP Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in c:\\users\\evans\\anaconda3\\lib\\site-packages (1.5.4)\n",
      "Requirement already satisfied: cftime in c:\\users\\evans\\anaconda3\\lib\\site-packages (from netCDF4) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9 in c:\\users\\evans\\anaconda3\\lib\\site-packages (from netCDF4) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "from matplotlib import gridspec\n",
    "import netCDF4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching ride from: https://surf.smartfin.org/ride/15962\n",
      "fetching ocean data from: https://surf.smartfin.org/media/201902/google_105349665704999793400_0006667E229D_190208171724_Ocean.CSV\n",
      "fetching motion data from: https://surf.smartfin.org/media/201902/google_105349665704999793400_0006667E229D_190208171724_Motion.CSV\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Latitude'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0dadf17182d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mride\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rides\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mride_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'15962'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mride\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ride_timeframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mride_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'15692'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Smartfin\\smartfin_module\\smartfin_ride_api.py\u001b[0m in \u001b[0;36mget_rides\u001b[1;34m(self, ride_ids, data, convert_imu)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# load in dataframes if not in directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_rides\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m# fill returns with dataframes of ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Smartfin\\smartfin_module\\smartfin_ride_api.py\u001b[0m in \u001b[0;36madd_rides\u001b[1;34m(self, ride_ids)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \"\"\"\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mride\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mride_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_ride\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Smartfin\\smartfin_module\\smartfin_ride_api.py\u001b[0m in \u001b[0;36madd_ride\u001b[1;34m(self, ride_id, convert_imu)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;31m# convert latitude and longitude values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[0mmdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlatitude\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100000\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlatitude\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m             \u001b[0mmdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlongitude\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100000\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlongitude\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Latitude'"
     ]
    }
   ],
   "source": [
    "# TODO: load station number and yeardate based on smartfin ride date input\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../smartfin_module')\n",
    "\n",
    "from smartfin_ride_api import Ride\n",
    "\n",
    "ride = Ride()\n",
    "dfs = ride.get_rides(ride_ids=['15962'])\n",
    "times = ride.get_ride_timeframes(ride_ids=['15692'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs['15962']\n",
    "latitude = df.iloc[0]['Latitude']\n",
    "longitude = df.iloc[0]['Longitude']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get nearest buoy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_nearest_buoy(latitude, longitude):\n",
    "    \n",
    "    # get all active buoys with archived data\n",
    "    # CDIP active buoys URL\n",
    "    url=\"http://cdip.ucsd.edu/m/deployment/station_view/?mode=active\"\n",
    "\n",
    "    # Make a GET request to fetch the raw HTML content\n",
    "    html_content = requests.get(url).text\n",
    "\n",
    "    # Parse the html content\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    table = soup.find(\"table\")\n",
    "    table_data = table.tbody.find_all(\"tr\")  # contains 2 rows\n",
    "    stns = []\n",
    "    for node in table_data:\n",
    "        try:\n",
    "            stn = node.findAll('td', text=True)[0]\n",
    "            stns.append(stn.text.strip(' '))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    stns.reverse()\n",
    "    \n",
    "    # intialize the lowest distance to be some rediculously big number\n",
    "    lowest_distance = 1000000000\n",
    "    stn = -1\n",
    "    longitude /= 100000\n",
    "    latitude /= 100000\n",
    "    \n",
    "    # iterate through 0-450 (station numbers are from 28-433 with gaps in between)\n",
    "    for i in stns:\n",
    "        \n",
    "        # format i into a 3 digit string\n",
    "        i = str(i)\n",
    "        if len(i) == 1:\n",
    "            i = '00' + i\n",
    "        elif len(i) == 2:\n",
    "            i = '0' + i\n",
    "        \n",
    "        # see if there is a station with the current iteration number\n",
    "        try:\n",
    "            data_url = 'http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/' + i + 'p1/' + i+ 'p1_historic.nc'\n",
    "            nc = netCDF4.Dataset(data_url)\n",
    "\n",
    "            # get latitude and longitude of current station\n",
    "            nc_latitude = nc.variables['metaStationLatitude'][:]\n",
    "            nc_longitude = nc.variables['metaStationLongitude'][:]\n",
    "\n",
    "            print(i)\n",
    "            \n",
    "            # if the current station distance is lower than the lowest distance so far, save it\n",
    "            curr_distance = abs(nc_latitude - latitude) + abs(nc_longitude - longitude)\n",
    "            if curr_distance < lowest_distance:\n",
    "                lowest_distance = curr_distance\n",
    "                stn = i\n",
    "                print('lower: ', i)\n",
    "                print(curr_distance)\n",
    "            else: continue\n",
    "\n",
    "        except OSError as err:\n",
    "            print(\"Unexpected error: \", err)\n",
    "            continue\n",
    "    \n",
    "    if stn == -1:\n",
    "        print('no station found error')\n",
    "    return stn\n",
    "            \n",
    "\n",
    "stn = get_nearest_buoy(latitude, longitude)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get latitude and longitude of all buoys via webscrape to avoid too many netCDF requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p onclick=\"plot_param('waveHs'); href_append('waveHs');\">\n",
       " <span class=\"label label-success\">Significant Wave Height</span>\n",
       " <strong>0.90</strong> m / <strong>2.95</strong> ft\n",
       "         </p>,\n",
       " <p onclick=\"plot_param('waveTp'); href_append('waveTp');\">\n",
       " <span class=\"label label-warning\">Peak Period</span> <strong>16.67</strong> s\n",
       "         </p>,\n",
       " <p onclick=\"plot_param('waveDp'); href_append('waveDp');\">\n",
       " <span class=\"label label-danger\">Direction</span> <strong>218</strong>° \n",
       "             <span class=\"glyphicon glyphicon-arrow-down text-muted\" style=\"transform: rotate(217.71875deg); display:inline-block; text-align:center; width:2em; font-size: 0.9em;\"></span>\n",
       " </p>,\n",
       " <p onclick=\"plot_param('sstSeaSurfaceTemperature'); href_append('sstSeaSurfaceTemperature');\">\n",
       " <span class=\"label label-info\">Temperature</span> <strong>23.2</strong> °C\n",
       "             / <strong>73.7</strong> °F\n",
       "         </p>,\n",
       " <p><strong><span class=\"dateTimeUTC\">Aug 20, 18:23</span></strong>\n",
       " <a href=\"/m/regions/\"><span class=\"glyphicon glyphicon-time\"></span></a>\n",
       " <select aria-label=\"timezone\" id=\"tz\" onchange=\"cdip.setSession('tz', tz.value); cdip.ChangeTimeZone(cdip.dateTimeUTC, tz.value);\">\n",
       " <option selected=\"\" value=\"UTC\">UTC</option>\n",
       " <option value=\"Pacific/Guam\">Guam</option>\n",
       " <option value=\"Pacific/Majuro\">Majuro</option>\n",
       " <option value=\"US/Samoa\">Samoa</option>\n",
       " <option value=\"US/Hawaii\">Hawaii</option>\n",
       " <option value=\"US/Alaska\">Alaska</option>\n",
       " <option value=\"US/Pacific\">Pacific</option>\n",
       " <option value=\"US/Mountain\">Mountain</option>\n",
       " <option value=\"US/Central\">Central</option>\n",
       " <option value=\"US/Eastern\">Eastern</option>\n",
       " <option value=\"America/Sao_Paulo\">Brazil</option>\n",
       " </select>\n",
       " </p>,\n",
       " <p>Latitude: <a href=\"/m/gps/?stn=028p1&amp;deploy_label=d20\">\n",
       " <strong>33.85535</strong></a> N</p>,\n",
       " <p>Longitude: <a href=\"/m/gps/?stn=028p1&amp;deploy_label=d20\"><strong>\n",
       "             -118.63438</strong></a> E</p>,\n",
       " <p>Depth: <strong>370</strong>\n",
       "             m / <strong>1214 </strong> ft</p>,\n",
       " <p><a href=\"/m/deployment/?stn=028p1\">Previous Deployments</a></p>,\n",
       " <p>NDBC (WMO Identifier): <a href=\"//www.ndbc.noaa.gov/station_page.php/?station=46221\">46221</a></p>,\n",
       " <p><a href=\"/m/documents/data_access.html#data-use-and-acknowledgements\">Data Use and Acknowledgements</a></p>,\n",
       " <p>\n",
       " <a class=\"btn btn-primary btn-block\" href=\"//cdip.ucsd.edu/themes/cdip?d2=p70:s:028&amp;pub_set=public&amp;zoom=auto&amp;regions=all&amp;units=standard&amp;high=6.096&amp;palette=cdip_classic&amp;ll_fmt=dm&amp;numcolorbands=10&amp;tz=UTC\">Classic\n",
       "                         View <span aria-hidden=\"true\" class=\"glyphicon glyphicon-random\"></span></a>\n",
       " </p>,\n",
       " <p>CDIP's historic products and station information</p>,\n",
       " <p>\n",
       " <a class=\"btn btn-info btn-block\" href=\"//thredds.cdip.ucsd.edu/thredds/catalog/cdip/realtime/catalog.html?dataset=CDIP_Realtime/028p1_rt.nc\">THREDDS\n",
       "                         Server</a>\n",
       " </p>,\n",
       " <p>A web server that provides metadata and data access for CDIP's NetCDF datasets, using\n",
       "                     OPeNDAP, OGC WMS and WCS, HTTP, and other remote data access protocols.\n",
       "                 </p>,\n",
       " <p>\n",
       " <a class=\"btn btn-success btn-block\" href=\"//cdip.ucsd.edu/data_access/ndar.cdip?\">NDAR</a>\n",
       " </p>,\n",
       " <p>A web utility for accessing data from CDIP's NetCDF data files. It\n",
       "                     serves station data in traditional CDIP formats, as well handling newer\n",
       "                     formats and wavecdf datasets from any source.\n",
       "                 </p>,\n",
       " <p>\n",
       " <a class=\"btn btn-warning btn-block\" href=\"//cdip.ucsd.edu/rss/028.xml\">RSS</a>\n",
       " </p>,\n",
       " <p>\n",
       " <img alt=\"RSS Icon\" border=\"0\" src=\"/m/static/img/rss.png\" width=\"20\"/>\n",
       "                     Download an RSS reader (aka \"aggregator\") for your phone or add an \n",
       "                     RSS extension to your browser then click on the above button.\n",
       "                 </p>,\n",
       " <p>\n",
       " <a class=\"tn\" href=\"/m/about/contact/\">Contact Us</a>\n",
       " </p>,\n",
       " <p class=\"text-center\">\n",
       "                      \n",
       "                 </p>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all active buoys with archived data\n",
    "# CDIP active buoys URL\n",
    "url=\"http://cdip.ucsd.edu/m/deployment/station_view/?mode=active\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse the html content\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "table = soup.find(\"table\")\n",
    "table_data = table.tbody.find_all(\"tr\")  # contains 2 rows\n",
    "stns = []\n",
    "for node in table_data:\n",
    "    try:\n",
    "        stn = node.findAll('td', text=True)[0]\n",
    "        stns.append(stn.text.strip(' '))\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "# format i into a 3 digit string\n",
    "for i in range(len(stns)):\n",
    "    stn = str(stns[i])\n",
    "    if len(stn) == 1:\n",
    "        stn = '00' + stn\n",
    "    elif len(stn) == 2:\n",
    "        stn = '0' + stn\n",
    "    stns[i] = stn\n",
    "    \n",
    "# for stn in stns:\n",
    "stn_url = f'https://cdip.ucsd.edu/m/products/?stn={stns[0]}p1'\n",
    "station_content_html = requests.get(stn_url).text\n",
    "stn_soup = BeautifulSoup(station_content_html, 'html')\n",
    "latitude = stn_soup.find_all('p', text='Latitude: <a href=\"/m/gps/?stn=028p1&amp;deploy_label=d20\">\n",
    " <strong>33.85535</strong></a> N')\n",
    "latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find active buoy numbers function used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CDIP Archived Dataset URL\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url=\"http://cdip.ucsd.edu/m/deployment/station_view/?mode=active\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse the html content\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "table = soup.find(\"table\")\n",
    "table_data = table.tbody.find_all(\"tr\")  # contains 2 rows\n",
    "nums = []\n",
    "for node in table_data:\n",
    "    try:\n",
    "        num = node.findAll('td', text=True)[0]\n",
    "        nums.append(num.text.strip(' '))\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read vars from CDIP THREDDS Server Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netCDF data object fetched from CDIP API\n",
    "data_url = 'http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/' + '124' + 'p1/' + '124'+ 'p1_historic.nc'\n",
    "\n",
    "nc = netCDF4.Dataset(data_url)\n",
    "\n",
    "# UNIX based time from 1991-yeardate in 30 minute increments\n",
    "ncTime = nc.variables['sstTime'][:]\n",
    "timeall = [datetime.datetime.fromtimestamp(t) for t in ncTime]\n",
    "waveTime = nc.variables['waveTime'][:]\n",
    "\n",
    "print(len(waveTime))\n",
    "\n",
    "# wave heights\n",
    "Hs = nc.variables['waveHs']\n",
    "print(\"hs length: \", len(Hs))\n",
    "print(\"ncTime length: \", len(ncTime))\n",
    "\n",
    "print(ncTime)\n",
    "print(waveTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest value in ncTime array to inputted UNIX Timestamp\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    print('index:',idx)\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert human time to UNIX time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert human-formatted date to UNIX timestamp\n",
    "def getUnixTimestamp(humanTime,dateFormat):\n",
    "    unixTimestamp = int(time.mktime(datetime.datetime.strptime(humanTime, dateFormat).timetuple()))\n",
    "    print('humanTime: ', humanTime)\n",
    "    print('UNIX Timestamp: ', unixTimestamp)\n",
    "    return unixTimestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Index Values\n",
    "\n",
    "Find the UNIX values that correspond to start (Day 1) and end (Day 28) dates for each month. Then find the array index numbers for each UNIX value within the 'ncTime' arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create array of lists of Hs data for each month \n",
    "\n",
    "# timeindex_start = []\n",
    "# timeindex_end = []\n",
    "# monthcount = 0\n",
    "\n",
    "unixstart = getUnixTimestamp(start_date, \"%d/%m/%Y %H:%M:%S\")\n",
    "nearest_date = find_nearest(waveTime, unixstart)  # Find the closest unix timestamp\n",
    "start_index = np.where(waveTime==nearest_date)[0][0]  # Grab the index number of found date\n",
    "\n",
    "unixend = getUnixTimestamp(end_date,\"%d/%m/%Y %H:%M:%S\")\n",
    "future_date = find_nearest(waveTime, unixend)  # Find the closest unix timestamp\n",
    "end_index = np.where(waveTime==future_date)[0][0]  # Grab the index number of found date    \n",
    "\n",
    "# timeindex_start.append(start_index) # Append 'month start date' and 'month end date' index numbers for each month to corresponding array\n",
    "# timeindex_end.append(end_index)\n",
    "# 1536718563\n",
    "# 1536723495\n",
    "# 309100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index -= 14\n",
    "end_index -= 14\n",
    "\n",
    "print(end_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean wave heights of each month\n",
    "\n",
    "Create array of month-long chunks of Hs data, to be plotted as a series of boxplots. Use a for-loop to cycle through the Hs variable and define each month-long array using the above-specified time index numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data = []\n",
    "i = 0\n",
    "print(start_index - end_index)\n",
    "print('Hs length: ', len(Hs))\n",
    "print('times length: ', len(ncTime))\n",
    "# all wave height averages per 30 minute increments over each month\n",
    "ride_hs = Hs[start_index:end_index]\n",
    "i = i+1\n",
    "print(len(ride_hs))\n",
    "print(ride_hs)\n",
    "    \n",
    "# append each dataset to the box data\n",
    "box_data.append(ride_hs)\n",
    "    \n",
    "# calculate means of each month dataset in box_data\n",
    "means = np.asarray([np.mean(m) for m in box_data]) \n",
    "\n",
    "# Round each monthly mean value to 2 decimal points, for plotting\n",
    "meansround = [round(k,2) for k in means] \n",
    "print(means)\n",
    "print(ride_hs.mean())\n",
    "print('mean wave height:', meansround)\n",
    "ride_hs.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of instances of the variable being incorporated into each month-long average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlengths = []\n",
    "j = 0\n",
    "\n",
    "for Hs in range(len(Hs[start_index])):\n",
    "    \n",
    "    # how many readings were recorded during that month\n",
    "    monthlenHs = len(Hs[start_index[j]:start_index[j]])\n",
    "    j = j+1\n",
    "    monthlengths.append(monthlenHs)\n",
    "    \n",
    "monthlengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Wave Time-Series\n",
    "* Create boxplot graph of month-long datasets\n",
    "* Each box includes:\n",
    "    - Median (red line)\n",
    "    - 25th and 75th percentiles (top and bottom of box)\n",
    "    - Remaining data within 1.5L above and below (whiskers) the quartiles, where L = length (m) from 25th to 75th percentile\n",
    "    - Outliers (red crosses) - data beyond whiskers\n",
    "    - Mean position (green line) and value (green number)\n",
    "* Adjust colors and labels of graphical display\n",
    "* Include a second plot of a sample 'legend' boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create overall figure and specify size, and grid to specify positions of subplots\n",
    "fig = plt.figure(figsize=(12,15)) \n",
    "gs = gridspec.GridSpec(2,2,height_ratios=[5,1]) \n",
    "\n",
    "\n",
    "# Create a dataset for sample 'legend' boxplot, to go underneath actual boxplot\n",
    "bp_sample2 = np.random.normal(2.5,0.5,500)\n",
    "\n",
    "\n",
    "# Create two subplots - actual monthly-averaged data (top) and example 'legend' boxplot (bottom)\n",
    "\n",
    "# Subplot of monthly-averaged boxplot data\n",
    "bp = plt.subplot(gs[0,:])\n",
    "bp_data = bp.boxplot(box_data) # Add 'meanlineprops' to include the above-defined properties\n",
    "bp.scatter(months,means,marker=\"_\",color='g',linewidths=2.5,s=900) # Overlay monthly means as green lines using 'scatter' function.\n",
    "\n",
    "# Subplot to show example 'legend' boxplot below actual monthly-averaged boxplot graph\n",
    "bp2 = plt.subplot(gs[1,1:-1])\n",
    "bp2_example = bp2.boxplot(bp_sample2,vert=False) # Plot horizontal example boxplot with labels\n",
    "bp2.scatter(2.3,1,marker=\"|\",color='g',linewidths=2.5,s=400)\n",
    "\n",
    "\n",
    "# Add values of monthly means as text\n",
    "for i, txt in enumerate(meansround):\n",
    "    bp.annotate(txt, (months[i],means[i]),fontsize=12,horizontalalignment='center',verticalalignment='bottom',color='g')\n",
    "\n",
    "    \n",
    "# Get positions of Median, Quartiles and Outliers to use in 'legend' text labels \n",
    "for line in bp2_example['medians']:\n",
    "    xm, ym = line.get_xydata()[0] # location of Median line   \n",
    "for line in bp2_example['boxes']:\n",
    "    xb, yb = line.get_xydata()[0] # location of Box edges (Quartiles)\n",
    "for line in bp2_example['whiskers']:\n",
    "    xw, yw = line.get_xydata()[0] # location of Whisker ends (Outliers)\n",
    "    \n",
    "\n",
    "# Add text labels for 'Median', Mean', '25th/75th %iles' and 'Outliers' to subplot2, to create sample 'legend' boxplot\n",
    "bp2.annotate(\"Median\",[xm,ym-0.3*ym],fontsize=14,color='r')\n",
    "bp2.annotate(\"Mean\",[2.2,0.65],fontsize=14,color='g')\n",
    "bp2.annotate(\"25%ile\",[xb-0.01*xb,yb-0.15*yb],fontsize=12)\n",
    "bp2.annotate(\"75%ile\",[xb+0.2*xb,yb-0.15*yb],fontsize=12)\n",
    "bp2.annotate(\"Outliers\",[xw+0.38*xw,yw-0.3*yw],fontsize=14,color='r')\n",
    "\n",
    " \n",
    "# Set colors of box aspects for top subplot    \n",
    "pylab.setp(bp_data['boxes'], color='black')\n",
    "pylab.setp(bp_data['whiskers'], color='black')\n",
    "pylab.setp(bp_data['fliers'], color='r')\n",
    "\n",
    "\n",
    "# Set colors of box aspects for bottom (sample) subplot   \n",
    "pylab.setp(bp2_example['boxes'], color='black')\n",
    "pylab.setp(bp2_example['whiskers'], color='black')\n",
    "pylab.setp(bp2_example['fliers'], color='r')\n",
    "\n",
    "\n",
    "# Set Titles\n",
    "plt.suptitle(buoytitle, fontsize=30, y=0.97) # Overall plot title using 'buoytitle' variable\n",
    "bp.set_title(\"Significant Wave Height by month for \" + year_date, fontsize=20, y=1.01) # Subtitle for top plot\n",
    "# bp2.set_title(\"Sample Boxplot\", fontsize=16, y=1.02) # Subtitle for bottom plot\n",
    "\n",
    "\n",
    "# Set axes labels and ticks\n",
    "bp.set_xticklabels(['ride'],fontsize=12)\n",
    "bp.set_ylabel('Significant Wave Height, Hs (m)', fontsize=20)\n",
    "bp.tick_params(axis='y', which='major', labelsize=12, right='off')\n",
    "bp.tick_params(axis='x', which='major', labelsize=12, top='off')\n",
    "\n",
    "\n",
    "# Create a second row of x-axis labels for top subplot\n",
    "newax = bp.twiny()\n",
    "newax.xaxis.set_ticks_position('bottom')\n",
    "newax.xaxis.set_label_position('bottom')\n",
    "newax.spines['bottom'].set_position(('outward',25))\n",
    "newax.set_xticklabels(monthlengths,fontsize=10)\n",
    "\n",
    "\n",
    "# Plot horizontal gridlines onto top subplot\n",
    "bp.grid(axis='y', which='major', color='b', linestyle='-', alpha=0.25)\n",
    "\n",
    "\n",
    "# Remove tickmarks from bottom subplot\n",
    "bp2.axes.get_xaxis().set_visible(False)\n",
    "bp2.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
